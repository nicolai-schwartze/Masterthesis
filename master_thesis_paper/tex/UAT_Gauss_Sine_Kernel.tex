\documentclass[./\jobname.tex]{subfiles}
\begin{document}
	
\section{Universial Approximation Theorem for GSK}
\label{chap:gsin_approximation_theorem}

The Gauss kernel is able to approximate all functions that are part of the Lebesgue space $f(\mathbf{x}) \in L^1(\mathbb{R}^n)$ arbitrarily close. This has been proven by various works (\cite{park_universal_1991}, \cite{hangelbroek_nonlinear_2010}). In particular, \cite{park_universal_1991} extends the universal approximation theorem to other kernels. The following paragraphs show that the \gls{gsk} fulfils the posed conditions and thus can benefit from the approximation theorem.  

\begin{equation}
\label{eq:gsin_kernel_theoretical_notes}
gsk(\mathbf{x}) = \omega e^{-\gamma ||\mathbf{x} - \mathbf{c}||^2} sin(f ||\mathbf{x} - \mathbf{c}||^2 - \varphi)
\end{equation}

To prove that the universal approximation theorem is also applicable to the \gls{gsk}, it must comply with the conditions placed by \cite{park_universal_1991}. At first, a kernel, in this case the $gsk(\mathbf{x})$, must be continuous and bounded. This already restricts $\gamma > 0$. However, \cite{chaquet_using_2019} found that not placing any limits on the parameters results in a better performance. Thus, this constraint is not implemented in the current version of the algorithm. Secondly, the integral over the whole domain of the kernel $K(\mathbf{x})$ must not be $0$. Thus, it needs to be shown that 

\begin{equation}
\int_{\mathbf{x} = -\mathbf{\infty}}^{\infty} gsk(\mathbf{x}) \text{ } d\mathbf{x} \neq 0
\end{equation} 

Intuitively, the next restriction on $\omega \neq 0$ is found. 

To simplify the following calculations, the \gls{gsk} is rewritten into polar coordinates. Further, the offsets by $c_0$ and $c_1$ are accounted for by an appropriate coordinate transformation. This results in 

\begin{equation}
\lim_{t \to \infty} \int_{r=0}^{t} \int_{\theta = 0}^{2 \pi} e^{-\gamma(r^2)} sin(f r^2 - \varphi) r \text{ } dr \text{ } d\theta
\end{equation}

Since the kernel is radial symmetric and thus has no dependency on $\theta$, the respective integral can be solved immediately which results in a multiplicative factor of $2 \pi$. The integral can be further simplified by substituting $r^2 = u$.
The resulting expression can be solved with ``integration by part'' $\int f(u) \frac{g(u)}{du} = f(u) g(u) - \int g(u) \frac{f(u)}{du}$. The formula has to be applied twice. The same integral is retrieved. Thus, the equation can be rearranged and solved for the integral. Considering the constant factors and the integral limits gives 

\begin{equation}
\lim_{t \to \infty} \frac{\pi e^{-\gamma r^2}(- \gamma sin(f r^2 - \varphi) - f cos(f r^2 - \varphi))}{ \gamma^2 + f^2} + C \text{ } \Bigg|_{r=0}^{t}.
\end{equation}

To resolve the limit of the function towards $\infty$, the function value must be bounded. Therefore, $\gamma$ must be positive, which is already required. Finally, this results in 

\begin{equation}
	\frac{-\pi (\gamma sin(\varphi) + f cos(\varphi))}{\gamma^2 + f^2} \neq 0.
\end{equation}

This places more constraints on the parameter of the \gls{gsk} as seen in the equation \eqref{eq:gsk_param_restrictions} below. 

\begin{equation}
\label{eq:gsk_param_restrictions}
	\begin{split}
	\gamma & > 0 \\
	\omega & \neq 0 \\
	\gamma & sin(\varphi) + f cos(\varphi) \neq 0 \\
	\end{split}
\end{equation}

These restrictions on the parameters could be enforced during the optimisation process. They could further be used to limit the search dimension. Thus, other optimisation algorithms that are good at handling constraints must be used. 



\end{document}