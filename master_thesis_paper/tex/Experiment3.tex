\documentclass[./\jobname.tex]{subfiles}
\begin{document}
\section {Experiment 3: Gauss-Sinus Kernel}
\label{chap:experimet_3}
Up until now, the results on \gls{pde} 5 were always considerably worse than on all other testbed functions. The idea discussed in this section is the usage of a new kernel. Theoretically, the Gauss Sine kernel (\gls{gsk}) should be able to solve the testbed \gls{pde}s 0A and 0B exactly.  
\subsection{Hypotheses}
Attempting to solve \gls{pde} 5 with more \gls{nfe} results in a worse solution quality. The adaptive kernel scheme could not improve the results. This means that the fitness function must be reconsidered. A simple approach to change the fitness function is by introducing a new kernel type. The \gls{gsk} has the features of a Gauss kernel and a sine function and is potentially able to approximate more \gls{pde} solutions. This experiment tries to answer the question if the new \gls{gsk} kernel type can effectively improve the results on \gls{pde} 5. 
\subsection{Experiment Setup}

Machine 2 runs the experiment at the full computational budget of $10^6$ \gls{nfe}. Because the last experiment was not entirely conclusive, only a memetic pJADE without kernel-adaption is tested. Since the new kernel has 6 parameters, the dimension and the population size change. To ensure that the algorithm is able to solve \gls{pde} 0A, 5 \gls{gsk} are used. This results in a dimension of 30 parameters and a population size of 60. All other parameters for the experiments are taken from table \ref{tab:ci_parameter}. 

\subsection{Results}
The following table shows the statistical test. The comparison between the \gls{gsk} and the \gls{gak} on the memetic parallel JADE is shown in table \ref{tab:compare_mpj_mpjgsk_10^6}. The comparison is done with a budget of $10^6$ \gls{nfe}. 
\begin{table}[h]
	\centering
	\noindent\adjustbox{max width=\linewidth}{
		\begin{tabular}{|c|c|c|c|c|l|}
			
			\hline
			\rowcolor[HTML]{\farbeTabA}
			
			Algorithm & \multicolumn{2}{|c|}{parallel JADE \gls{gak} $10^6$ \gls{nfe}} & \multicolumn{2}{|c|}{parallel JADE \gls{gsk} $10^6$ \gls{nfe}} & \\ \hline
			stat & mean & median & mean & median & Wilcoxon Test \\ \hline \hline
			\gls{pde} 0A & 0.6939 $\pm$ 0.6635 & 0.9243 & 0.8106 $\pm$ 0.7929 & 0.6765 & unsig. undecided \\ \hline
			\gls{pde} 0B & 0.2809 $\pm$ 0.3071 & 0.2035 & 0.0667 $\pm$ 0.0470 & 0.0614 & sig. better \\ \hline
			\gls{pde} 1 & 0.0239 $\pm$ 0.0467 & 0.0146 & 0.1665 $\pm$ 0.1015 & 0.1952 & sig. worse \\ \hline
			\gls{pde} 2 & 0.0300 $\pm$ 0.0157 & 0.0255 & 0.0448 $\pm$ 0.0224 & 0.0416 & unsig. worse \\ \hline
			\gls{pde} 3 & 0.0371 $\pm$ 0.0206 & 0.0295 & 0.0263 $\pm$ 0.0111 & 0.0269 & unsig. better \\ \hline
			\gls{pde} 4 & 0.0505 $\pm$ 0.0121 & 0.0481 & 0.0470 $\pm$ 0.0078 & 0.0458 & unsig. better \\ \hline
			\gls{pde} 5 & 1.2030 $\pm$ 0.0465 & 1.2053 & 0.5860 $\pm$ 0.2149 & 0.6841 & sig. better \\ \hline
			\gls{pde} 6 & 0.5814 $\pm$ 1.3550 & 0.0000 & 3.7321 $\pm$ 0.6397 & 3.9079 & sig. worse\\ \hline 
			\gls{pde} 7 & 0.0228 $\pm$ 0.0025 & 0.0226 & 0.0243 $\pm$ 0.0046 & 0.0241 & unsig. worse\\ \hline 
			\gls{pde} 8 & 0.2167 $\pm$ 0.0017 & 0.2169 & 0.2154 $\pm$ 0.0018 & 0.2150 & sig. better\\ \hline
			\gls{pde} 9 & 0.0426 $\pm$ 0.0115 & 0.0463 & 0.0351 $\pm$ 0.0099 & 0.0333 & unsig. better\\ \hline
			
		\end{tabular}
	}
	\unterschrift{Statistical comparison of the the parallel JADE using the \gls{gak} and the \gls{gsk}.}{}{}
	\label{tab:compare_mpj_mpjgsk_10^6}
\end{table}
\newpage
\subsection{Discussion}
\subsubsection{PDE 5}
The hypothesis of the \gls{gsk} is that it significantly increases the approximation quality of \gls{pde} 5. Further, it should overcome the phenomenon where the L2 norm increases with more \gls{nfe}. As table \ref{tab:compare_mpj_mpjgsk_10^6} shows, the results are indeed significantly better. Again, this can be confirmed from a visual perspective by looking at the 3D plot of the approximation. Figure \ref{fig:pde5_ex3_compare_best_worst} depicts the best and the worst approximation of the 20 replications. Although the results are clearly better and the global structure is described more accurately, the \gls{ci} solver can not compete with the \gls{fem} solver. 
\begin{figure}[h]
	\centering
	\begin{subfigure}[b]{0.3333\linewidth}
		\centering
		\includegraphics[width=1\textwidth]{../../code/experiments/experiment_3/pde5_best_solution_non-adaptive.pdf}
		\caption{best run  \gls{gsk} \\L2 norm: 0.252574}
		\label{fig:pde5_ex3_worst_solution_non-adaptive}
	\end{subfigure}% 
	%
	\begin{subfigure}[b]{0.3333\linewidth}
		\centering
		\includegraphics[width=1\textwidth]{../../code/experiments/experiment_3/pde5_worst_solution_non-adaptive.pdf}
		\caption{worst run \gls{gsk} \\L2 norm: 0.883869}
		\label{fig:pde5_ex3_best_solution_adaptive}
	\end{subfigure}%
	%
	\begin{subfigure}[b]{0.3333\linewidth}
		\centering
		\includegraphics[width=1\textwidth]{../../code/testbed/pde5/sol_pde_5.pdf}
		\caption{solution \\ \gls{pde} 5.}
		\label{fig:pde5_analytical_solution_3}
	\end{subfigure}%
	\unterschrift{Comparison of the best and the worst result generated by memetic pJADE with \gls{gsk} after $10^6$ \gls{nfe}. }{}{}%
	\label{fig:pde5_ex3_compare_best_worst}
\end{figure}
The following histograms in figure \ref{fig:pde5_L2norm_histogram_gsk} compare the experimental distribution of the L2 norm with the \gls{gak} and the \gls{gsk}. As inferred from the Wilcoxon test, the distributions are significantly different. Further, the mean and the median of the ``\gls{gsk}-data'' are smaller than the same statistical indicators of the ``\gls{gak}-data''. The histogram of the fitness values is shown in figure \ref{fig:pde5_fitness_histogram_gsk}. Contrary, the fitness values of the \gls{gak} are smaller than the fitness values of the \gls{gsk}. Because the fitness function changes with the usage of the \gls{gsk}, the numerical values can not be compared directly. 
\begin{figure}[h]
	\centering
	\begin{subfigure}[b]{0.5\linewidth}
		\centering
		\includegraphics[width=1\textwidth]{../../code/experiments/experiment_3/pde5_non-adaptive_histogram_fit.pdf}
		\caption{Histogram of fitness value using \gls{gsk} and \gls{gak}.}
		\label{fig:pde5_fitness_histogram_gsk}
	\end{subfigure}%
	%
	\begin{subfigure}[b]{0.48\linewidth}
		\centering
		\includegraphics[width=1\textwidth]{../../code/experiments/experiment_3/pde5_non-adaptive_histogram_L2.pdf}
		\caption{Histogram of L2 norm using \gls{gsk} and \gls{gak}.}
		\label{fig:pde5_L2norm_histogram_gsk}
	\end{subfigure}% 
	\unterschrift{Histograms of \gls{gsk} and \gls{gak} L2 norm and fitness value on \gls{pde} 5 after $10^6$ \gls{nfe}. }{}{}%
	\label{fig:pde5_ex3_histogram}
\end{figure}
Similar to the plot in section \ref{chap:ex0_pde5}, figure \ref{fig:ex3_pde5_gsk_fit_vs_l2} connects the L2 norm of one individual with its fitness value at every generation. Although the effect of a raising L2 norm with increasing \gls{nfe} is mitigated, it can be seen that the best quality is not reached after $10^6$ \gls{nfe}. After generation 5000, the L2 norm settles in at around 0.4, while the fitness value continues to decrease. 
\begin{figure}[h]
	\centering
	\noindent\adjustbox{max width=0.8\linewidth}{
		\includegraphics[width=\textwidth]{../../code/experiments/misc/pde5_gsk_fit_l2_history.pdf}
	}
	\unterschrift{Fitness value and L2 Norm of an exemplary individual at every generation on \mbox{\gls{pde} 5} using a \gls{gsk}. }{}{}
		\label{fig:ex3_pde5_gsk_fit_vs_l2}
\end{figure}
This again shows that a good fitness value does not necessarily indicate a good approximation quality. Although this property is only shown on \gls{pde} 5, it might also be true on other \gls{pde}s. This issue demonstrates that the fitness function suffers from a fundamental problem, but currently this is the best indicator for good solutions that only use the information posed in the original problem definition. It can be concluded that choosing an appropriate kernel is not trivial, especially in the common case where the analytical solution to the \gls{pde} is not known.  
\end{document}