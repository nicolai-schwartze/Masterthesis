
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%									State of the Art         								   %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



@article{storn_differential_1997,
	title = {Differential Evolution – A Simple and Efficient Heuristic for global Optimization over Continuous Spaces},
	volume = {11},
	issn = {1573-2916},
	url = {https://doi.org/10.1023/A:1008202821328},
	doi = {10.1023/A:1008202821328},
	abstract = {A new heuristic approach for minimizing possiblynonlinear and non-differentiable continuous spacefunctions is presented. By means of an extensivetestbed it is demonstrated that the new methodconverges faster and with more certainty than manyother acclaimed global optimization methods. The newmethod requires few control variables, is robust, easyto use, and lends itself very well to parallelcomputation.},
	pages = {341--359},
	number = {4},
	journaltitle = {Journal of Global Optimization},
	shortjournal = {Journal of Global Optimization},
	author = {Storn, Rainer and Price, Kenneth},
	urldate = {2019-04-05},
	date = {1997-12-01},
	langid = {english},
	file = {Storn und Price - 1997 - Differential Evolution – A Simple and Efficient He.pdf:C\:\\Users\\Nicolai\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\P7XLVZJN\\Storn und Price - 1997 - Differential Evolution – A Simple and Efficient He.pdf:application/pdf}
}

@inproceedings{tanabe_improving_2014,
	title = {Improving the search performance of {SHADE} using linear population size reduction},
	doi = {10.1109/CEC.2014.6900380},
	abstract = {{SHADE} is an adaptive {DE} which incorporates success-history based parameter adaptation and one of the state-of-the-art {DE} algorithms. This paper proposes L-{SHADE}, which further extends {SHADE} with Linear Population Size Reduction ({LPSR}), which continually decreases the population size according to a linear function. We evaluated the performance of L-{SHADE} on {CEC}2014 benchmarks and compared its search performance with state-of-the-art {DE} algorithms, as well as the state-of-the-art restart {CMA}-{ES} variants. The experimental results show that L-{SHADE} is quite competitive with state-of-the-art evolutionary algorithms.},
	eventtitle = {2014 {IEEE} Congress on Evolutionary Computation ({CEC})},
	pages = {1658--1665},
	booktitle = {2014 {IEEE} Congress on Evolutionary Computation ({CEC})},
	author = {Tanabe, Ryoji and Fukunaga, Alex S.},
	date = {2014-07},
	note = {{ISSN}: 1941-0026},
	keywords = {Differential Evolution, L-{SHADE}, Self-Adaption, {SHADE}},
	file = {Tanabe und Fukunaga - 2014 - Improving the search performance of SHADE using li.pdf:C\:\\Users\\Nicolai\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\MSVCJJA3\\Tanabe und Fukunaga - 2014 - Improving the search performance of SHADE using li.pdf:application/pdf}
}

@article{fateh_differential_2019,
	title = {Differential evolution based computation intelligence solver for elliptic partial differential equations},
	volume = {20},
	issn = {2095-9230},
	url = {https://doi.org/10.1631/FITEE.1900221},
	doi = {10.1631/FITEE.1900221},
	abstract = {A differential evolution based methodology is introduced for the solution of elliptic partial differential equations ({PDEs}) with Dirichlet and/or Neumann boundary conditions. The solutions evolve over bounded domains throughout the interior nodes by minimization of nodal deviations among the population. The elliptic {PDEs} are replaced by the corresponding system of finite difference approximation, yielding an expression for nodal residues. The global residue is declared as the root-mean-square value of the nodal residues and taken as the cost function. The standard differential evolution is then used for the solution of elliptic {PDEs} by conversion to a minimization problem of the global residue. A set of benchmark problems consisting of both linear and nonlinear elliptic {PDEs} has been considered for validation, proving the effectiveness of the proposed algorithm. To demonstrate its robustness, sensitivity analysis has been carried out for various differential evolution operators and parameters. Comparison of the differential evolution based computed nodal values with the corresponding data obtained using the exact analytical expressions shows the accuracy and convergence of the proposed methodology.},
	pages = {1445--1456},
	number = {10},
	journaltitle = {Frontiers of Information Technology \& Electronic Engineering},
	shortjournal = {Frontiers Inf Technol Electronic Eng},
	author = {Fateh, Muhammad Faisal and Zameer, Aneela and Mirza, Sikander M. and Mirza, Nasir M. and Aslam, Muhammad Saeed and Raja, Muhammad Asif Zahoor},
	urldate = {2020-02-11},
	date = {2019-10-01},
	langid = {english},
	keywords = {Differential Evolution, Finite Difference, Elliptic {PDE}, Good Quality},
	file = {Fateh et al. - 2019 - Differential evolution based computation intellige.pdf:C\:\\Users\\Nicolai\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\RMI9HVII\\Fateh et al. - 2019 - Differential evolution based computation intellige.pdf:application/pdf}
}

@article{tsoulos_solving_2006,
	title = {Solving differential equations with genetic programming},
	volume = {7},
	issn = {1573-7632},
	url = {https://doi.org/10.1007/s10710-006-7009-y},
	doi = {10.1007/s10710-006-7009-y},
	abstract = {A novel method for solving ordinary and partial differential equations, based on grammatical evolution is presented. The method forms generations of trial solutions expressed in an analytical closed form. Several examples are worked out and in most cases the exact solution is recovered. When the solution cannot be expressed in a closed analytical form then our method produces an approximation with a controlled level of accuracy. We report results on several problems to illustrate the potential of this approach.},
	pages = {33--54},
	number = {1},
	journaltitle = {Genetic Programming and Evolvable Machines},
	shortjournal = {Genet Program Evolvable Mach},
	author = {Tsoulos, I. G. and Lagaris, I. E.},
	urldate = {2020-02-15},
	date = {2006-03-01},
	langid = {english},
	keywords = {Testbed Functions, Grammatical Evolution, Analytic Solution},
	file = {Tsoulos und Lagaris - 2006 - Solving differential equations with genetic progra.pdf:C\:\\Users\\Nicolai\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\YJQT9M4T\\Tsoulos und Lagaris - 2006 - Solving differential equations with genetic progra.pdf:application/pdf}
}

@inproceedings{mastorakis_unstable_2006,
	location = {Elounda, Greece},
	title = {Unstable Ordinary Differential Equations: Solution via Genetic Algorithms and the method of Nelder-Mead},
	url = {https://www.researchgate.net/profile/Nikos_Mastorakis2/publication/261859052_Unstable_ordinary_differential_equations_Solution_via_genetic_algorithms_and_the_method_of_Nelder-Mead/links/573b254e08ae9f741b2d7853.pdf},
	eventtitle = {{WSEAS} Int. Conf. on Systems Theory \& Scientific Computation},
	pages = {7},
	author = {Mastorakis, Nikos E},
	urldate = {2020-02-19},
	date = {2006-08-21},
	langid = {english},
	keywords = {Genetic Algorithm, Unstable {ODE}, Runge Kutta, Downhill Simplex, Adam Bashforth},
	file = {Mastorakis - 2006 - Unstable Ordinary Differential Equations Solution.pdf:C\:\\Users\\Nicolai\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\Z7S8L7FM\\Mastorakis - 2006 - Unstable Ordinary Differential Equations Solution.pdf:application/pdf}
}

@online{langtangen_introduction_2013,
	title = {Introduction to finite element methods},
	url = {http://hplgit.github.io/INF5620/doc/pub/sphinx-fem/index.html},
	titleaddon = {Introduction to finite element methods},
	type = {Tutorial},
	author = {Langtangen, Hans Petter},
	urldate = {2020-02-21},
	date = {2013-12-16},
	keywords = {Theory, Finite Element Method}
}

@article{panagant_solving_2014,
	title = {Solving Partial Differential Equations Using a New Differential Evolution Algorithm},
	url = {https://www.hindawi.com/journals/mpe/2014/747490/},
	abstract = {This paper proposes an alternative meshless approach to solve partial differential equations ({PDEs}). With a global approximate function being defined, a partial differential equation problem is converted into an optimisation problem with equality constraints from {PDE} boundary conditions. An evolutionary algorithm ({EA}) is employed to search for the optimum solution. For this approach, the most difficult task is the low convergence rate of {EA} which consequently results in poor {PDE} solution approximation. However, its attractiveness remains due to the nature of a soft computing technique in {EA}. The algorithm can be used to tackle almost any kind of optimisation problem with simple evolutionary operation, which means it is mathematically simpler to use. A new efficient differential evolution ({DE}) is presented and used to solve a number of the partial differential equations. The results obtained are illustrated and compared with exact solutions. It is shown that the proposed method has a potential to be a future meshless tool provided that the search performance of {EA} is greatly enhanced.},
	number = {2014},
	journaltitle = {Mathematical Problems in Engineering},
	author = {Panagant, Natee and Bureerat, Sujin},
	urldate = {2020-02-27},
	date = {2014},
	langid = {english},
	doi = {https://doi.org/10.1155/2014/747490},
	doi = {https://doi.org/10.1155/2014/747490},
	note = {{ISSN}: 1024-123X
Library Catalog: www.hindawi.com
Pages: e747490
Publisher: Hindawi
Volume: 2014},
	keywords = {Differential Evolution, {PDE}, Polynomial Approximation},
	file = {Panagant und Bureerat - 2014 - Solving Partial Differential Equations Using a New.pdf:C\:\\Users\\Nicolai\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\GEA7TI7B\\Panagant und Bureerat - 2014 - Solving Partial Differential Equations Using a New.pdf:application/pdf}
}

@article{babaei_general_2013,
	title = {A general approach to approximate solutions of nonlinear differential equations using particle swarm optimization},
	volume = {13},
	issn = {1568-4946},
	url = {http://www.sciencedirect.com/science/article/pii/S1568494613000598},
	doi = {10.1016/j.asoc.2013.02.005},
	abstract = {A general algorithm is presented to approximately solve a great variety of linear and nonlinear ordinary differential equations ({ODEs}) independent of their form, order, and given conditions. The {ODEs} are formulated as optimization problem. Some basic fundamentals from different areas of mathematics are coupled with each other to effectively cope with the propounded problem. The Fourier series expansion, calculus of variation, and particle swarm optimization ({PSO}) are employed in the formulation of the problem. Both boundary value problems ({BVPs}) and initial value problems ({IVPs}) are treated in the same way. Boundary and initial conditions are both modeled as constraints of the optimization problem. The constraints are imposed through the penalty function strategy. The penalty function in cooperation with weighted-residual functional constitutes fitness function which is central concept in evolutionary algorithms. The robust metaheuristic optimization technique of the {PSO} is employed to find the solution of the extended variational problem. Finally, illustrative examples demonstrate practicality and efficiency of the presented algorithm as well as its wide operational domain.},
	pages = {3354--3365},
	number = {7},
	journaltitle = {Applied Soft Computing},
	shortjournal = {Applied Soft Computing},
	author = {Babaei, M.},
	urldate = {2020-02-27},
	date = {2013-07-01},
	langid = {english},
	keywords = {Good Quality, Fourier Series, Particle Swarm Optimisation},
	file = {Babaei - 2013 - A general approach to approximate solutions of non.pdf:C\:\\Users\\Nicolai\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\FJK6YSUZ\\Babaei - 2013 - A general approach to approximate solutions of non.pdf:application/pdf}
}

@inproceedings{howard_genetic_2001,
	location = {San Francisco, California},
	title = {Genetic Programming solution of the convection-diffusion equation},
	isbn = {978-1-55860-774-3},
	series = {{GECCO}'01},
	abstract = {A version of Genetic Programming ({GP}) is proposed for the solution of the steady-state convection-diffusion equation which neither requires sampling points to evaluate fitness nor application of the chain rule to {GP} trees for obtaining the derivatives. The method is successfully applied to the equation in one space dimension.},
	pages = {34--41},
	booktitle = {Proceedings of the 3rd Annual Conference on Genetic and Evolutionary Computation},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Howard, Daniel and Roberts, Simon C.},
	urldate = {2020-02-27},
	date = {2001-07-07},
	keywords = {Genetic Programming, Polynomial Approximation},
	file = {Howard und Roberts - 2001 - Genetic Programming solution of the convection-dif.pdf:C\:\\Users\\Nicolai\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\8FRMJTAQ\\Howard und Roberts - 2001 - Genetic Programming solution of the convection-dif.pdf:application/pdf}
}

@article{chaquet_using_2019,
	title = {Using Covariance Matrix Adaptation Evolution Strategies for solving different types of differential equations},
	volume = {23},
	issn = {1433-7479},
	url = {https://doi.org/10.1007/s00500-017-2888-9},
	doi = {10.1007/s00500-017-2888-9},
	abstract = {A novel mesh-free heuristic method for solving differential equations is proposed. The new approach can cope with linear, nonlinear, and partial differential equations ({DE}), and systems of {DEs}. Candidate solutions are expressed using a linear combination of kernel functions. Thus, the original problem is transformed into an optimization problem that consists in finding the parameters that define each kernel. The new optimization problem is solved applying a Covariance Matrix Adaptation Evolution Strategy. To increase the accuracy of the results, a Downhill Simplex local search is applied to the best solution found by the mentioned evolutionary algorithm. Our method is applied to 32 differential equations extracted from the literature. All problems are successfully solved, achieving competitive accuracy levels when compared to other heuristic methods. A simple comparison with numerical methods is performed using two partial differential equations to show the pros and cons of the proposed algorithm. To verify the potential of this approach with a more practical problem, an electric circuit is analyzed in depth. The method can obtain the dynamic behavior of the circuit in a parametric way, taking into account different component values.},
	pages = {1643--1666},
	number = {5},
	journaltitle = {Soft Computing},
	shortjournal = {Soft Comput},
	author = {Chaquet, Jose M. and Carmona, Enrique J.},
	urldate = {2020-03-02},
	date = {2019-03-01},
	langid = {english},
	keywords = {Good Quality, {CMA}-{ES}, Radial Basis Functions, Literature Survey},
	file = {Chaquet und Carmona - 2019 - Using Covariance Matrix Adaptation Evolution Strat.pdf:C\:\\Users\\Nicolai\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\YKK6UD9T\\Chaquet und Carmona - 2019 - Using Covariance Matrix Adaptation Evolution Strat.pdf:application/pdf}
}

@article{sadollah_metaheuristic_2017,
	title = {Metaheuristic optimisation methods for approximate solving of singular boundary value problems},
	volume = {29},
	issn = {0952-813X},
	url = {https://doi.org/10.1080/0952813X.2016.1259271},
	doi = {10.1080/0952813X.2016.1259271},
	abstract = {This paper presents a novel approximation technique based on metaheuristics and weighted residual function ({WRF}) for tackling singular boundary value problems ({BVPs}) arising in engineering and science. With the aid of certain fundamental concepts of mathematics, Fourier series expansion, and metaheuristic optimisation algorithms, singular {BVPs} can be approximated as an optimisation problem with boundary conditions as constraints. The target is to minimise the {WRF} (i.e. error function) constructed in approximation of {BVPs}. The scheme involves generational distance metric for quality evaluation of the approximate solutions against exact solutions (i.e. error evaluator metric). Four test problems including two linear and two non-linear singular {BVPs} are considered in this paper to check the efficiency and accuracy of the proposed algorithm. The optimisation task is performed using three different optimisers including the particle swarm optimisation, the water cycle algorithm, and the harmony search algorithm. Optimisation results obtained show that the suggested technique can be successfully applied for approximate solving of singular {BVPs}.},
	pages = {823--842},
	number = {4},
	journaltitle = {Journal of Experimental \& Theoretical Artificial Intelligence},
	author = {Sadollah, Ali and Yadav, Neha and Gao, Kaizhou and Su, Rong},
	urldate = {2020-03-02},
	date = {2017-07-04},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/0952813X.2016.1259271},
	keywords = {Good Quality, Fourier Series, Particle Swarm Optimisation, Harmony Search, Water Cycle Algorithm},
	file = {Sadollah et al. - 2017 - Metaheuristic optimisation methods for approximate.pdf:C\:\\Users\\Nicolai\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\96ZHFX98\\Sadollah et al. - 2017 - Metaheuristic optimisation methods for approximate.pdf:application/pdf}
}

@article{kirstukas_hybrid_2005,
	title = {A hybrid genetic programming approach for the analytical solution of differential equations},
	volume = {34},
	issn = {0308-1079},
	url = {https://doi.org/10.1080/03081070500065676},
	doi = {10.1080/03081070500065676},
	abstract = {This paper presents a novel addition to the current genetic programming techniques for solving differential equations. Rather than using numerical approximation of derivatives during fitness evaluation, automatically computed analytical derivatives of the candidate solutions are employed. Because analytical derivatives are used, symbolic constants can be incorporated in the solution. This permits the development of a single solution for a range of material properties, boundary conditions or other design parameters. Additionally, for the special case of linear differential equations, a modified Gram–Schmidt algorithm is used to reduce the set of general solutions located by genetic programming to a basis set.},
	pages = {279--299},
	number = {3},
	journaltitle = {International Journal of General Systems},
	author = {Kirstukas, Steven J. and Bryden, Kenneth M. and Ashlock, Daniel A.},
	urldate = {2020-03-02},
	date = {2005-06-01},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/03081070500065676},
	keywords = {Genetic Programming, Gram-Schmitt},
	file = {Kirstukas et al. - 2005 - A hybrid genetic programming approach for the anal.pdf:C\:\\Users\\Nicolai\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\7ILYD4BM\\Kirstukas et al. - 2005 - A hybrid genetic programming approach for the anal.pdf:application/pdf}
}

@article{chaquet_solving_2012,
	title = {Solving differential equations with Fourier series and Evolution Strategies},
	volume = {12},
	issn = {1568-4946},
	url = {http://www.sciencedirect.com/science/article/pii/S1568494612002505},
	doi = {10.1016/j.asoc.2012.05.014},
	abstract = {A novel mesh-free approach for solving differential equations based on Evolution Strategies ({ESs}) is presented. Any structure is assumed in the equations making the process general and suitable for linear and nonlinear ordinary and partial differential equations ({ODEs} and {PDEs}), as well as systems of ordinary differential equations ({SODEs}). Candidate solutions are expressed as partial sums of Fourier series. Taking advantage of the decreasing absolute value of the harmonic coefficients with the harmonic order, several {ES} steps are performed. Harmonic coefficients are taken into account one by one starting with the lower order ones. Experimental results are reported on several problems extracted from the literature to illustrate the potential of the proposed approach. Two cases (an initial value problem and a boundary condition problem) have been solved using numerical methods and a quantitative comparative is performed. In terms of accuracy and storing requirements the proposed approach outperforms the numerical algorithm.},
	pages = {3051--3062},
	number = {9},
	journaltitle = {Applied Soft Computing},
	shortjournal = {Applied Soft Computing},
	author = {Chaquet, Jose M. and Carmona, Enrique J.},
	urldate = {2020-03-02},
	date = {2012-09-01},
	langid = {english},
	keywords = {Evolution Strategies, Good Quality, Fourier Series, Literature Survey},
	file = {Chaquet und Carmona - 2012 - Solving differential equations with Fourier series.pdf:C\:\\Users\\Nicolai\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\V8A3RWU5\\Chaquet und Carmona - 2012 - Solving differential equations with Fourier series.pdf:application/pdf}
}

@article{howard_genetic_2011,
	title = {Genetic programming of the stochastic interpolation framework: convection–diffusion equation},
	volume = {15},
	issn = {1433-7479},
	url = {https://doi.org/10.1007/s00500-009-0520-3},
	doi = {10.1007/s00500-009-0520-3},
	shorttitle = {Genetic programming of the stochastic interpolation framework},
	abstract = {The stochastic interpolation ({SI}) framework of function recovery from input data comprises a de-convolution step followed by a convolution step with row stochastic matrices generated by a mollifier, such as a probability density function. The choice of a mollifier and of how it gets weighted, offers unprecedented flexibility to vary both the interpolation character and the extent of influence of neighbouring data values. In this respect, a soft computing method such as a genetic algorithm or heuristic method may assist applications that model complex or unknown relationships between data by tuning the parameters, functional and component choices inherent in {SI}. Alternatively or additionally, the input data itself can be reverse engineered to recover a function that satisfies properties, as illustrated in this paper with a genetic programming scheme that enables {SI} to recover the analytical solution to a two-point boundary value convection–diffusion differential equation. If further developed, this nascent solution method could serve as an alternative to the weighted residual methods, as these are known to have inherent mathematical difficulties.},
	pages = {71--78},
	number = {1},
	journaltitle = {Soft Computing},
	shortjournal = {Soft Comput},
	author = {Howard, Daniel and Brezulianu, Adrian and Kolibal, Joseph},
	urldate = {2020-03-14},
	date = {2011-01-01},
	langid = {english},
	keywords = {Finite Difference, Genetic Programming},
	file = {Howard et al. - 2011 - Genetic programming of the stochastic interpolatio.pdf:C\:\\Users\\Nicolai\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\W5PFUCHX\\Howard et al. - 2011 - Genetic programming of the stochastic interpolatio.pdf:application/pdf}
}

@article{sobester_genetic_2008,
	title = {Genetic Programming Approaches for Solving Elliptic Partial Differential Equations},
	volume = {12},
	issn = {1941-0026},
	doi = {10.1109/TEVC.2007.908467},
	abstract = {In this paper, we propose a technique based on genetic programming ({GP}) for meshfree solution of elliptic partial differential equations. We employ the least-squares collocation principle to define an appropriate objective function, which is optimized using {GP}. Two approaches are presented for the repair of the symbolic expression for the field variables evolved by the {GP} algorithm to ensure that the governing equations as well as the boundary conditions are satisfied. In the case of problems defined on geometrically simple domains, we augment the solution evolved by {GP} with additional terms, such that the boundary conditions are satisfied by construction. To satisfy the boundary conditions for geometrically irregular domains, we combine the {GP} model with a radial basis function network. We improve the computational efficiency and accuracy of both techniques with gradient boosting, a technique originally developed by the machine learning community. Numerical studies are presented for operator problems on regular and irregular boundaries to illustrate the performance of the proposed algorithms.},
	pages = {469--478},
	number = {4},
	journaltitle = {{IEEE} Transactions on Evolutionary Computation},
	author = {Sobester, {AndrÁs} and Nair, Prasanth B. and Keane, Andy J.},
	date = {2008-08},
	note = {Conference Name: {IEEE} Transactions on Evolutionary Computation},
	keywords = {Good Quality, Genetic Programming},
	file = {Sobester et al. - 2008 - Genetic Programming Approaches for Solving Ellipti.pdf:C\:\\Users\\Nicolai\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\MQ7Q5N76\\Sobester et al. - 2008 - Genetic Programming Approaches for Solving Ellipti.pdf:application/pdf}
}

@book{finlayson_method_2013,
	title = {The Method of Weighted Residuals and Variational Principles},
	isbn = {978-1-61197-323-5},
	url = {https://epubs.siam.org/doi/book/10.1137/1.9781611973242},
	series = {Classics in Applied Mathematics},
	abstract = {This is a book for people who want to solve problems formulated as differential equations in science and engineering. The subject area is limited to fluid mechanics, heat and mass transfer. While making no pretense at completely covering these subjects and their relationship to variational principles and approximate methods, the book is intended to give the novice an introduction to the subject, and lead him through the difficult research problems being treated in the current literature. The first four chapters give a relatively simple treatment of many classical problems in the field. The literature is full of simple, one-term approximations, but the method of weighted residuals ({MWR}) can be used to obtain answers of any desired accuracy, and there are several methods specifically adapted to the computer. In many test cases {MWR} compares favorably to finite difference computations in that the {MWR} results are either more accurate or require less computation time to generate or both. Chapter 4 discusses the developments by Professor D. E. Abbott and his students at Purdue University on laminar boundary layer flows. Orthogonal collocation is illustrated in Chapter 5. This method was advanced in 1967 by Professor W. E. Stewart at the University of Wisconsin and J. V. Villadsen at Danmarks Tekniske Højskole, It drastically reduces the drudgery of setting up the problem, and, when applicable, is highly recommended. Chapter 6 studies the Galerkin method as applied to convective instability problems, where it proves effective and accurate. Chapters 5 and 7 relate {MWR} to finite element methods, which is a promising technique, especially for linear problems with irregular boundaries.},
	pagetotal = {427},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Finlayson, Bruce A.},
	urldate = {2020-03-19},
	date = {2013-12-18},
	doi = {10.1137/1.9781611973242},
	file = {Finlayson - 2013 - The Method of Weighted Residuals and Variational P.pdf:C\:\\Users\\Nicolai\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\M9E3HYQI\\Finlayson - 2013 - The Method of Weighted Residuals and Variational P.pdf:application/pdf}
}

@software{suganthan_p-n-suganthancec2019_2020,
	title = {P-N-Suganthan/{CEC}2019},
	url = {https://github.com/P-N-Suganthan/CEC2019},
	abstract = {100-Digit Competition. This folder includes {GECCO} 2019 and {SEMCCO} 2019 too, in addition to {CEC} 2019},
	author = {Suganthan, Ponnuthurai Nagaratnam},
	urldate = {2020-03-20},
	date = {2020-01-22},
	note = {original-date: 2019-07-01T11:46:13Z}
}

@inproceedings{tanabe_success-history_2013,
	title = {Success-history based parameter adaptation for Differential Evolution},
	doi = {10.1109/CEC.2013.6557555},
	abstract = {Differential Evolution is a simple, but effective approach for numerical optimization. Since the search efficiency of {DE} depends significantly on its control parameter settings, there has been much recent work on developing self-adaptive mechanisms for {DE}. We propose a new, parameter adaptation technique for {DE} which uses a historical memory of successful control parameter settings to guide the selection of future control parameter values. The proposed method is evaluated by comparison on 28 problems from the {CEC}2013 benchmark set, as well as {CEC}2005 benchmarks and the set of 13 classical benchmark problems. The experimental results show that a {DE} using our success-history based parameter adaptation method is competitive with the state-of-the-art {DE} algorithms.},
	eventtitle = {2013 {IEEE} Congress on Evolutionary Computation},
	pages = {71--78},
	booktitle = {2013 {IEEE} Congress on Evolutionary Computation},
	author = {Tanabe, Ryoji and Fukunaga, Alex},
	date = {2013-06},
	note = {{ISSN}: 1941-0026},
	file = {Tanabe und Fukunaga - 2013 - Success-history based parameter adaptation for Dif.pdf:C\:\\Users\\Nicolai\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\T5YTE4LJ\\Tanabe und Fukunaga - 2013 - Success-history based parameter adaptation for Dif.pdf:application/pdf}
}

@article{zhang_jade_2009,
	title = {{JADE}: Adaptive Differential Evolution With Optional External Archive},
	volume = {13},
	issn = {1941-0026},
	doi = {10.1109/TEVC.2009.2014613},
	shorttitle = {{JADE}},
	abstract = {A new differential evolution ({DE}) algorithm, {JADE}, is proposed to improve optimization performance by implementing a new mutation strategy {ldquoDE}/current-to-p bestrdquo with optional external archive and updating control parameters in an adaptive manner. The {DE}/current-to-pbest is a generalization of the classic {ldquoDE}/current-to-best,rdquo while the optional archive operation utilizes historical data to provide information of progress direction. Both operations diversify the population and improve the convergence performance. The parameter adaptation automatically updates the control parameters to appropriate values and avoids a user's prior knowledge of the relationship between the parameter settings and the characteristics of optimization problems. It is thus helpful to improve the robustness of the algorithm. Simulation results show that {JADE} is better than, or at least comparable to, other classic or adaptive {DE} algorithms, the canonical particle swarm optimization, and other evolutionary algorithms from the literature in terms of convergence performance for a set of 20 benchmark problems. {JADE} with an external archive shows promising results for relatively high dimensional problems. In addition, it clearly shows that there is no fixed control parameter setting suitable for various problems or even at different optimization stages of a single problem.},
	pages = {945--958},
	number = {5},
	journaltitle = {{IEEE} Transactions on Evolutionary Computation},
	author = {Zhang, Jingqiao and Sanderson, Arthur C.},
	date = {2009-10},
	note = {Conference Name: {IEEE} Transactions on Evolutionary Computation},
	file = {Zhang und Sanderson - 2009 - JADE Adaptive Differential Evolution With Optiona.pdf:C\:\\Users\\Nicolai\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\ZVTQN6TQ\\Zhang und Sanderson - 2009 - JADE Adaptive Differential Evolution With Optiona.pdf:application/pdf}
}

@article{rajeev_s_discrete_1992,
	title = {Discrete Optimization of Structures Using Genetic Algorithms},
	volume = {118},
	url = {https://ascelibrary.org/doi/abs/10.1061/(ASCE)0733-9445(1992)118:5(1233)},
	doi = {10.1061/(ASCE)0733-9445(1992)118:5(1233)},
	pages = {1233--1250},
	number = {5},
	journaltitle = {Journal of Structural Engineering},
	shortjournal = {Journal of Structural Engineering},
	author = {{Rajeev S.} and {Krishnamoorthy C. S.}},
	urldate = {2020-03-23},
	date = {1992-05-01},
	note = {Publisher: American Society of Civil Engineers},
	file = {Rajeev S. und Krishnamoorthy C. S. - 1992 - Discrete Optimization of Structures Using Genetic .pdf:C\:\\Users\\Nicolai\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\Q6N9E6ZJ\\Rajeev S. und Krishnamoorthy C. S. - 1992 - Discrete Optimization of Structures Using Genetic .pdf:application/pdf}
}

@software{schoberl_ngsolvengsolve_2020,
	title = {{NGSolve}/ngsolve},
	rights = {{LGPL}-2.1},
	url = {https://github.com/NGSolve/ngsolve},
	abstract = {Netgen/{NGSolve} is a high performance multiphysics finite element software. It is widely used to analyze models from solid mechanics, fluid dynamics and electromagnetics. Due to its flexible Pytho...},
	publisher = {{NGSolve}},
	author = {Schöberl, Joachim and Lackner, Christopher and Hochsteger, Matthias},
	urldate = {2020-04-02},
	date = {2020-04-02},
	note = {original-date: 2017-07-18T08:47:19Z}
}

@incollection{hansen_cma_2006,
	location = {Berlin, Heidelberg},
	title = {The {CMA} Evolution Strategy: A Comparing Review},
	isbn = {978-3-540-32494-2},
	url = {https://doi.org/10.1007/3-540-32494-1_4},
	series = {Studies in Fuzziness and Soft Computing},
	shorttitle = {The {CMA} Evolution Strategy},
	abstract = {{SummaryDerived} from the concept of self-adaptation in evolution strategies, the {CMA} (Covariance Matrix Adaptation) adapts the covariance matrix of a multi-variate normal search distribution. The {CMA} was originally designed to perform well with small populations. In this review, the argument starts out with large population sizes, reflecting recent extensions of the {CMA} algorithm. Commonalities and differences to continuous Estimation of Distribution Algorithms are analyzed. The aspects of reliability of the estimation, overall step size control, and independence from the coordinate system (invariance) become particularly important in small populations sizes. Consequently, performing the adaptation task with small populations is more intricate.},
	pages = {75--102},
	booktitle = {Towards a New Evolutionary Computation: Advances in the Estimation of Distribution Algorithms},
	publisher = {Springer},
	author = {Hansen, Nikolaus},
	editor = {Lozano, Jose A. and Larrañaga, Pedro and Inza, Iñaki and Bengoetxea, Endika},
	urldate = {2020-05-05},
	date = {2006},
	langid = {english},
	doi = {10.1007/3-540-32494-1_4},
	file = {Hansen - 2006 - The CMA Evolution Strategy A Comparing Review.pdf:C\:\\Users\\Nicolai\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\JVTYNKR5\\Hansen - 2006 - The CMA Evolution Strategy A Comparing Review.pdf:application/pdf}
}

@article{nelder_simplex_1965,
	title = {A Simplex Method for Function Minimization},
	volume = {7},
	issn = {0010-4620},
	url = {https://academic.oup.com/comjnl/article/7/4/308/354237},
	doi = {10.1093/comjnl/7.4.308},
	abstract = {Abstract.  A method is described for the minimization of a function of n variables, which depends on the comparison of function values at the (n + 1) vertices o},
	pages = {308--313},
	number = {4},
	journaltitle = {The Computer Journal},
	shortjournal = {Comput J},
	author = {Nelder, J. A. and Mead, R.},
	urldate = {2020-05-05},
	date = {1965-01-01},
	langid = {english},
	note = {Publisher: Oxford Academic},
	file = {Nelder und Mead - 1965 - A Simplex Method for Function Minimization.pdf:C\:\\Users\\Nicolai\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\QAL2B4HN\\Nelder und Mead - 1965 - A Simplex Method for Function Minimization.pdf:application/pdf}
}

@inproceedings{kennedy_particle_1995,
	title = {Particle swarm optimization},
	volume = {4},
	doi = {10.1109/ICNN.1995.488968},
	abstract = {A concept for the optimization of nonlinear functions using particle swarm methodology is introduced. The evolution of several paradigms is outlined, and an implementation of one of the paradigms is discussed. Benchmark testing of the paradigm is described, and applications, including nonlinear function optimization and neural network training, are proposed. The relationships between particle swarm optimization and both artificial life and genetic algorithms are described.},
	eventtitle = {Proceedings of {ICNN}'95 - International Conference on Neural Networks},
	pages = {1942--1948 vol.4},
	booktitle = {Proceedings of {ICNN}'95 - International Conference on Neural Networks},
	author = {Kennedy, J. and Eberhart, R.},
	date = {1995-11},
	file = {Kennedy und Eberhart - 1995 - Particle swarm optimization.pdf:C\:\\Users\\Nicolai\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\3EM6ZM54\\Kennedy und Eberhart - 1995 - Particle swarm optimization.pdf:application/pdf}
}

@book{koza_genetic_1992,
	location = {Cambridge, {MA}, {USA}},
	title = {Genetic programming: on the programming of computers by means of natural selection},
	isbn = {978-0-262-11170-6},
	shorttitle = {Genetic programming},
	publisher = {{MIT} Press},
	author = {Koza, John R.},
	date = {1992},
	file = {Koza - 1992 - Genetic programming on the programming of compute.pdf:C\:\\Users\\Nicolai\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\TYMVAE23\\Koza - 1992 - Genetic programming on the programming of compute.pdf:application/pdf}
}

@article{geem_new_2001,
	title = {A New Heuristic Optimization Algorithm: Harmony Search},
	volume = {76},
	issn = {0037-5497},
	url = {https://doi.org/10.1177/003754970107600201},
	doi = {10.1177/003754970107600201},
	shorttitle = {A New Heuristic Optimization Algorithm},
	abstract = {Many optimization problems in various fields have been solved using diverse optimization al gorithms. Traditional optimization techniques such as linear programming ({LP}), non-linear programming ({NLP}), and dynamic program ming ({DP}) have had major roles in solving these problems. However, their drawbacks generate demand for other types of algorithms, such as heuristic optimization approaches (simulated annealing, tabu search, and evolutionary algo rithms). However, there are still some possibili ties of devising new heuristic algorithms based on analogies with natural or artificial phenom ena. A new heuristic algorithm, mimicking the improvisation of music players, has been devel oped and named Harmony Search ({HS}). The performance of the algorithm is illustrated with a traveling salesman problem ({TSP}), a specific academic optimization problem, and a least-cost pipe network design problem.},
	pages = {60--68},
	number = {2},
	journaltitle = {{SIMULATION}},
	shortjournal = {{SIMULATION}},
	author = {Geem, Zong Woo and Kim, Joong Hoon and Loganathan, G.V.},
	urldate = {2020-05-05},
	date = {2001-02-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications Ltd {STM}},
	file = {Geem et al. - 2001 - A New Heuristic Optimization Algorithm Harmony Se.pdf:C\:\\Users\\Nicolai\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\RH63AXP7\\Geem et al. - 2001 - A New Heuristic Optimization Algorithm Harmony Se.pdf:application/pdf}
}

@article{eskandar_water_2012,
	title = {Water cycle algorithm – A novel metaheuristic optimization method for solving constrained engineering optimization problems},
	volume = {110-111},
	issn = {0045-7949},
	url = {http://www.sciencedirect.com/science/article/pii/S0045794912001770},
	doi = {10.1016/j.compstruc.2012.07.010},
	abstract = {This paper presents a new optimization technique called water cycle algorithm ({WCA}) which is applied to a number of constrained optimization and engineering design problems. The fundamental concepts and ideas which underlie the proposed method is inspired from nature and based on the observation of water cycle process and how rivers and streams flow to the sea in the real world. A comparative study has been carried out to show the effectiveness of the {WCA} over other well-known optimizers in terms of computational effort (measures as number of function evaluations) and function value (accuracy) in this paper.},
	pages = {151--166},
	journaltitle = {Computers \& Structures},
	shortjournal = {Computers \& Structures},
	author = {Eskandar, Hadi and Sadollah, Ali and Bahreininejad, Ardeshir and Hamdi, Mohd},
	urldate = {2020-05-05},
	date = {2012-11-01},
	langid = {english},
	file = {Eskandar et al. - 2012 - Water cycle algorithm – A novel metaheuristic opti.pdf:C\:\\Users\\Nicolai\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\TIKHFMZA\\Eskandar et al. - 2012 - Water cycle algorithm – A novel metaheuristic opti.pdf:application/pdf}
}

@inproceedings{ryan_grammatical_1998,
	location = {Berlin, Heidelberg},
	title = {Grammatical evolution: Evolving programs for an arbitrary language},
	isbn = {978-3-540-69758-9},
	doi = {10.1007/BFb0055930},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Grammatical evolution},
	abstract = {We describe a Genetic Algorithm that can evolve complete programs. Using a variable length linear genome to govern how a Backus Naur Form grammar definition is mapped to a program, expressions and programs of arbitrary complexity may be evolved. Other automatic programming methods are described, before our system, Grammatical Evolution, is applied to a symbolic regression problem.},
	pages = {83--96},
	booktitle = {Genetic Programming},
	publisher = {Springer},
	author = {Ryan, Conor and Collins, {JJ} and Neill, Michael O.},
	editor = {Banzhaf, Wolfgang and Poli, Riccardo and Schoenauer, Marc and Fogarty, Terence C.},
	date = {1998},
	langid = {english},
	file = {Ryan et al. - 1998 - Grammatical evolution Evolving programs for an ar.pdf:C\:\\Users\\Nicolai\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\9HR6ANDN\\Ryan et al. - 1998 - Grammatical evolution Evolving programs for an ar.pdf:application/pdf}
}

@article{goldberg_messy_1989,
	title = {Messy Genetic Algorithms: Motivation, Analysis, and First Results},
	shorttitle = {Messy Genetic Algorithms},
	abstract = {This paper defines and explores a somewhat different type of genetic algorithm ({GA})-a messy genetic algorithm ({mGA}). Messy {GAs} process variable-length strings that may be either under- or overspecified with respect to the problem being solved. As nature has formed its genotypes by progressing from simple to more complex life forms, messy {GAs} solve problems by combining relatively short, well-tested building blocks to form longer, more complex strings that increasingly cover all features of a problem. This approach stands in contrast to the usual fixed-length, fixed-coding genetic algorithm, where the existence of the requisite tight linkage is taken for granted or ignored altogether. To compare the two approaches, a 30-bit, order-three-deceptive problem is searched using a simple {GA} and a messy {GA}. Using a random but fixed ordering of the bits, the simple {GA} makes errors at roughly three-quarters of its positions; under a worst-case ordering, the simple {GA} errs at all positions. In contrast to the simple {GA} results, the messy {GA} repeatedly solves the same problem to optimality. Prior to this time, no {GA} had ever solved a provably difficult problem to optimality without prior knowledge of good string arrangements. The {mGA} presented herein repeatedly achieves globally optimal results without such knowledge, and it does so at the very first generation in which strings are long enough to cover the problem. The solution of a difficult nonlinear problem to optimality suggests that messy {GAs} can solve more difficult problems than has been possible to date with other genetic algorithms. The ramifications of these techniques in search and machine learning are explored, including the possibility of messy floating-point codes, messy permutations, and messy classifiers.},
	journaltitle = {Complex Systems},
	author = {Goldberg, David E. and Korb, Bradley and Deb, Kalyanmoy},
	date = {1989}
}







%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%									Experiments Chapter								   %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



@misc{mitchell_nist_2018,
	title = {{NIST} {AMR} {Benchmarks}},
	url = {https://math.nist.gov/amr-benchmark/index.html},
	language = {en},
	urldate = {2020-02-21},
	journal = {NIST Adaptive Mesh Refinment Benchmark Problems},
	author = {Mitchell, William F.},
	month = mar,
	year = {2018},
	keywords = {Testbed Functions}
}

@misc{python_standard_library_gc_2020,
	type = {Documentation},
	title = {gc — {Garbage} {Collector} interface — {Python} 3.8.3 documentation},
	shorttitle = {Python {GC} {Interface}},
	url = {https://docs.python.org/3/library/gc.html},
	abstract = {Documentation of the garbage collector interface for Python 3.8.3. Describes the functions and variables exposed to the user.},
	language = {en},
	urldate = {2020-05-21},
	journal = {gc — Garbage Collector interface — Python 3.8.3 documentation},
	author = {Python Standard Library, Garbage Collector},
	month = may,
	year = {2020},
	file = {gc — Garbage Collector interface — Python 3.8.3 documentation:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\RN2WQY7L\\gc.html:text/html}
}

@misc{rodola_psutil_2020,
	type = {Documentation},
	title = {psutil documentation — psutil 5.7.1 documentation},
	shorttitle = {process utilities},
	url = {https://psutil.readthedocs.io/en/latest/},
	abstract = {Documentation of the processes and system utilization module for Python 3.4+. Describes the functions and variables exposed to the user.},
	language = {en},
	urldate = {2020-05-21},
	journal = {psutil documentation — psutil 5.7.1 documentation},
	author = {Rodola, Giampaolo},
	month = may,
	year = {2020},
	note = {https://github.com/giampaolo/psutil/blob/master/docs/index.rst}
}

@misc{python_standard_library_time_2020,
	type = {Documentation},
	title = {time — {Time} access and conversions — {Python} 3.8.3 documentation},
	shorttitle = {Python {Time} {Module}},
	url = {https://docs.python.org/3/library/time.html},
	abstract = {Documentation of the time module for Python 3.8.3. Describes the functions and variables exposed to the user.},
	language = {en},
	urldate = {2020-05-22},
	journal = {time — Time access and conversions — Python 3.8.3 documentation},
	author = {Python Standard Library, Time},
	month = may,
	year = {2020},
	file = {time — Time access and conversions — Python 3.8.3 documentation:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\EQ36EHPM\\time.html:text/html}
}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%									COCO BBOB Plots     								   %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


@software{nikolaus_hansen_2019_2594848,
  author       = {Nikolaus Hansen and
                  Dimo Brockhoff and
                  Olaf Mersmann and
                  Tea Tusar and
                  Dejan Tusar and
                  Ouassim Ait ElHara and
                  Phillipe R. Sampaio and
                  Asma Atamna and
                  Konstantinos Varelas and
                  Umut Batu and
                  Duc Manh Nguyen and
                  Filip Matzner and
                  Anne Auger},
  title        = {{COmparing Continuous Optimizers: numbbo/COCO on 
                   Github}},
  month        = mar,
  year         = 2019,
  publisher    = {Zenodo},
  version      = {v2.3},
  doi          = {10.5281/zenodo.2594848},
  url          = {https://doi.org/10.5281/zenodo.2594848}
}

