
@article{storn_differential_1997,
	title = {Differential {Evolution} – {A} {Simple} and {Efficient} {Heuristic} for global {Optimization} over {Continuous} {Spaces}},
	volume = {11},
	issn = {1573-2916},
	url = {https://doi.org/10.1023/A:1008202821328},
	doi = {10.1023/A:1008202821328},
	abstract = {A new heuristic approach for minimizing possiblynonlinear and non-differentiable continuous spacefunctions is presented. By means of an extensivetestbed it is demonstrated that the new methodconverges faster and with more certainty than manyother acclaimed global optimization methods. The newmethod requires few control variables, is robust, easyto use, and lends itself very well to parallelcomputation.},
	language = {en},
	number = {4},
	urldate = {2019-04-05},
	journal = {Journal of Global Optimization},
	author = {Storn, Rainer and Price, Kenneth},
	month = dec,
	year = {1997},
	pages = {341--359},
	file = {Storn und Price - 1997 - Differential Evolution – A Simple and Efficient He.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\P7XLVZJN\\Storn und Price - 1997 - Differential Evolution – A Simple and Efficient He.pdf:application/pdf}
}

@inproceedings{tanabe_improving_2014,
	title = {Improving the search performance of {SHADE} using linear population size reduction},
	doi = {10.1109/CEC.2014.6900380},
	abstract = {SHADE is an adaptive DE which incorporates success-history based parameter adaptation and one of the state-of-the-art DE algorithms. This paper proposes L-SHADE, which further extends SHADE with Linear Population Size Reduction (LPSR), which continually decreases the population size according to a linear function. We evaluated the performance of L-SHADE on CEC2014 benchmarks and compared its search performance with state-of-the-art DE algorithms, as well as the state-of-the-art restart CMA-ES variants. The experimental results show that L-SHADE is quite competitive with state-of-the-art evolutionary algorithms.},
	booktitle = {2014 {IEEE} {Congress} on {Evolutionary} {Computation} ({CEC})},
	author = {Tanabe, Ryoji and Fukunaga, Alex S.},
	month = jul,
	year = {2014},
	note = {ISSN: 1941-0026},
	keywords = {Differential Evolution, L-SHADE, Self-Adaption, SHADE},
	pages = {1658--1665},
	file = {Tanabe und Fukunaga - 2014 - Improving the search performance of SHADE using li.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\MSVCJJA3\\Tanabe und Fukunaga - 2014 - Improving the search performance of SHADE using li.pdf:application/pdf}
}

@misc{hu_sufficient_2013,
	type = {Research {Article}},
	title = {Sufficient {Conditions} for {Global} {Convergence} of {Differential} {Evolution} {Algorithm}},
	url = {https://www.hindawi.com/journals/jam/2013/193196/},
	abstract = {The differential evolution algorithm (DE) is one of the most powerful stochastic real-parameter optimization algorithms. The theoretical studies on DE have gradually attracted the attention of more and more researchers. However, few theoretical researches have been done to deal with the convergence conditions for DE. In this paper, a sufficient condition and a corollary for the convergence of DE to the global optima are derived by using the infinite product. A DE algorithm framework satisfying the convergence conditions is then established. It is also proved that the two common mutation operators satisfy the algorithm framework. Numerical experiments are conducted on two parts. One aims to visualize the process that five convergent DE based on the classical DE algorithms escape from a local optimal set on two low dimensional functions. The other tests the performance of a modified DE algorithm inspired of the convergent algorithm framework on the benchmarks of the CEC2005.},
	language = {en},
	urldate = {2020-02-11},
	journal = {Journal of Applied Mathematics},
	author = {Hu, Zhongbo and Xiong, Shengwu and Su, Qinghua and Zhang, Xiaowei},
	year = {2013},
	doi = {https://doi.org/10.1155/2013/193196},
	keywords = {Differential Evolution, Global Convergence, Theory},
	file = {Hu et al. - 2013 - Sufficient Conditions for Global Convergence of Di.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\BQBGCLNQ\\Hu et al. - 2013 - Sufficient Conditions for Global Convergence of Di.pdf:application/pdf}
}

@article{fateh_differential_2019,
	title = {Differential evolution based computation intelligence solver for elliptic partial differential equations},
	volume = {20},
	issn = {2095-9230},
	url = {https://doi.org/10.1631/FITEE.1900221},
	doi = {10.1631/FITEE.1900221},
	abstract = {A differential evolution based methodology is introduced for the solution of elliptic partial differential equations (PDEs) with Dirichlet and/or Neumann boundary conditions. The solutions evolve over bounded domains throughout the interior nodes by minimization of nodal deviations among the population. The elliptic PDEs are replaced by the corresponding system of finite difference approximation, yielding an expression for nodal residues. The global residue is declared as the root-mean-square value of the nodal residues and taken as the cost function. The standard differential evolution is then used for the solution of elliptic PDEs by conversion to a minimization problem of the global residue. A set of benchmark problems consisting of both linear and nonlinear elliptic PDEs has been considered for validation, proving the effectiveness of the proposed algorithm. To demonstrate its robustness, sensitivity analysis has been carried out for various differential evolution operators and parameters. Comparison of the differential evolution based computed nodal values with the corresponding data obtained using the exact analytical expressions shows the accuracy and convergence of the proposed methodology.},
	language = {en},
	number = {10},
	urldate = {2020-02-11},
	journal = {Frontiers of Information Technology \& Electronic Engineering},
	author = {Fateh, Muhammad Faisal and Zameer, Aneela and Mirza, Sikander M. and Mirza, Nasir M. and Aslam, Muhammad Saeed and Raja, Muhammad Asif Zahoor},
	month = oct,
	year = {2019},
	keywords = {Differential Evolution, Finite Difference, Elliptic PDE, Good Quality},
	pages = {1445--1456},
	annote = {use function value points over the domain as the design variables;
advantage: is not limited to smooth solutions;
disadvantage: search space very big},
	file = {Fateh et al. - 2019 - Differential evolution based computation intellige.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\RMI9HVII\\Fateh et al. - 2019 - Differential evolution based computation intellige.pdf:application/pdf}
}

@article{tsoulos_solving_2006,
	title = {Solving differential equations with genetic programming},
	volume = {7},
	issn = {1573-7632},
	url = {https://doi.org/10.1007/s10710-006-7009-y},
	doi = {10.1007/s10710-006-7009-y},
	abstract = {A novel method for solving ordinary and partial differential equations, based on grammatical evolution is presented. The method forms generations of trial solutions expressed in an analytical closed form. Several examples are worked out and in most cases the exact solution is recovered. When the solution cannot be expressed in a closed analytical form then our method produces an approximation with a controlled level of accuracy. We report results on several problems to illustrate the potential of this approach.},
	language = {en},
	number = {1},
	urldate = {2020-02-15},
	journal = {Genetic Programming and Evolvable Machines},
	author = {Tsoulos, I. G. and Lagaris, I. E.},
	month = mar,
	year = {2006},
	keywords = {Testbed Functions, Grammatical Evolution, Analytic Solution},
	pages = {33--54},
	annote = {Genetic Evolution is similar to GP but the candidates are represented as a vector instead of a tree
constructs an algebraic term as a closed trail solution
fitness function: trail-solution on equidistant points + on boundary
extensive experiments on ODE SODE and PDE, but only the results for ODE are promising},
	file = {Tsoulos und Lagaris - 2006 - Solving differential equations with genetic progra.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\YJQT9M4T\\Tsoulos und Lagaris - 2006 - Solving differential equations with genetic progra.pdf:application/pdf}
}

@inproceedings{mastorakis_unstable_2006,
	address = {Elounda, Greece},
	title = {Unstable {Ordinary} {Differential} {Equations}: {Solution} via {Genetic} {Algorithms} and the method of {Nelder}-{Mead}},
	url = {https://www.researchgate.net/profile/Nikos_Mastorakis2/publication/261859052_Unstable_ordinary_differential_equations_Solution_via_genetic_algorithms_and_the_method_of_Nelder-Mead/links/573b254e08ae9f741b2d7853.pdf},
	language = {en},
	urldate = {2020-02-19},
	author = {Mastorakis, Nikos E},
	month = aug,
	year = {2006},
	keywords = {Genetic Algorithm, Unstable ODE, Runge Kutta, Downhill Simplex, Adam Bashforth},
	pages = {7},
	annote = {uses a genetic algorithm for the global search and a Nelder-Mead (=Downhill Simplex) for the local search refinment
uses unstable ODE and PDEs, that are not solvable with finite difference methodes
the candidates are coded as the 5 parameters used of a 5th order polynomial
the boundary conditions are directly incorporated into the candidate, thus simplifying the fitness function
 },
	file = {Mastorakis - 2006 - Unstable Ordinary Differential Equations Solution.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\Z7S8L7FM\\Mastorakis - 2006 - Unstable Ordinary Differential Equations Solution.pdf:application/pdf}
}

@misc{langtangen_introduction_2013,
	type = {Tutorial},
	title = {Introduction to finite element methods},
	url = {http://hplgit.github.io/INF5620/doc/pub/sphinx-fem/index.html},
	urldate = {2020-02-21},
	journal = {Introduction to finite element methods},
	author = {Langtangen, Hans Petter},
	month = dec,
	year = {2013},
	keywords = {Theory, Finite Element Method}
}

@article{panagant_solving_2014,
	title = {Solving {Partial} {Differential} {Equations} {Using} a {New} {Differential} {Evolution} {Algorithm}},
	volume = {2014},
	issn = {1024-123X},
	url = {https://www.hindawi.com/journals/mpe/2014/747490/},
	abstract = {This paper proposes an alternative meshless approach to solve partial differential equations (PDEs). With a global approximate function being defined, a partial differential equation problem is converted into an optimisation problem with equality constraints from PDE boundary conditions. An evolutionary algorithm (EA) is employed to search for the optimum solution. For this approach, the most difficult task is the low convergence rate of EA which consequently results in poor PDE solution approximation. However, its attractiveness remains due to the nature of a soft computing technique in EA. The algorithm can be used to tackle almost any kind of optimisation problem with simple evolutionary operation, which means it is mathematically simpler to use. A new efficient differential evolution (DE) is presented and used to solve a number of the partial differential equations. The results obtained are illustrated and compared with exact solutions. It is shown that the proposed method has a potential to be a future meshless tool provided that the search performance of EA is greatly enhanced.},
	language = {en},
	number = {2014},
	urldate = {2020-02-27},
	journal = {Mathematical Problems in Engineering},
	author = {Panagant, Natee and Bureerat, Sujin},
	year = {2014},
	doi = {https://doi.org/10.1155/2014/747490},
	doi = {https://doi.org/10.1155/2014/747490},
	note = {Publisher: Hindawi},
	keywords = {Differential Evolution, PDE, Polynomial Approximation},
	pages = {e747490},
	annote = {optimisation algorithm: differential evolution, candidate representation as polynomial
uses 6 different PDEs to evaluate result
adds a member to the population in every generation, until a maximum population size is reached
the fitness function consists of the WRM for the inner points as well as a penalty term for the boundary condition},
	file = {Panagant und Bureerat - 2014 - Solving Partial Differential Equations Using a New.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\GEA7TI7B\\Panagant und Bureerat - 2014 - Solving Partial Differential Equations Using a New.pdf:application/pdf}
}

@article{babaei_general_2013,
	title = {A general approach to approximate solutions of nonlinear differential equations using particle swarm optimization},
	volume = {13},
	issn = {1568-4946},
	url = {http://www.sciencedirect.com/science/article/pii/S1568494613000598},
	doi = {10.1016/j.asoc.2013.02.005},
	abstract = {A general algorithm is presented to approximately solve a great variety of linear and nonlinear ordinary differential equations (ODEs) independent of their form, order, and given conditions. The ODEs are formulated as optimization problem. Some basic fundamentals from different areas of mathematics are coupled with each other to effectively cope with the propounded problem. The Fourier series expansion, calculus of variation, and particle swarm optimization (PSO) are employed in the formulation of the problem. Both boundary value problems (BVPs) and initial value problems (IVPs) are treated in the same way. Boundary and initial conditions are both modeled as constraints of the optimization problem. The constraints are imposed through the penalty function strategy. The penalty function in cooperation with weighted-residual functional constitutes fitness function which is central concept in evolutionary algorithms. The robust metaheuristic optimization technique of the PSO is employed to find the solution of the extended variational problem. Finally, illustrative examples demonstrate practicality and efficiency of the presented algorithm as well as its wide operational domain.},
	language = {en},
	number = {7},
	urldate = {2020-02-27},
	journal = {Applied Soft Computing},
	author = {Babaei, M.},
	month = jul,
	year = {2013},
	keywords = {Good Quality, Fourier Series, Particle Swarm Optimisation},
	pages = {3354--3365},
	annote = {uses particle swarm optimisation
uses fourier series to approximat the solution
fitness function is evaluated using an integration scheme instead of colloction points
formula
BVP is introduced using the penalty function of rajeev\_s\_discrete\_1992
 },
	file = {Babaei - 2013 - A general approach to approximate solutions of non.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\FJK6YSUZ\\Babaei - 2013 - A general approach to approximate solutions of non.pdf:application/pdf}
}

@inproceedings{howard_genetic_2001,
	address = {San Francisco, California},
	series = {{GECCO}'01},
	title = {Genetic {Programming} solution of the convection-diffusion equation},
	isbn = {978-1-55860-774-3},
	abstract = {A version of Genetic Programming (GP) is proposed for the solution of the steady-state convection-diffusion equation which neither requires sampling points to evaluate fitness nor application of the chain rule to GP trees for obtaining the derivatives. The method is successfully applied to the equation in one space dimension.},
	urldate = {2020-02-27},
	booktitle = {Proceedings of the 3rd {Annual} {Conference} on {Genetic} and {Evolutionary} {Computation}},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Howard, Daniel and Roberts, Simon C.},
	month = jul,
	year = {2001},
	keywords = {Genetic Programming, Polynomial Approximation},
	pages = {34--41},
	annote = {tries to solve a subset of convection-diffusion equations using genetic programming
the optimisation alogirhtm manipulates a polynomial of variable length -{\textgreater} thus GPmain advantage of polynomial: derivative can be represented as matrix multiplication
fitness function as simple squared of RHS, sampled at equidistant points},
	file = {Howard und Roberts - 2001 - Genetic Programming solution of the convection-dif.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\8FRMJTAQ\\Howard und Roberts - 2001 - Genetic Programming solution of the convection-dif.pdf:application/pdf}
}

@article{chaquet_using_2019,
	title = {Using {Covariance} {Matrix} {Adaptation} {Evolution} {Strategies} for solving different types of differential equations},
	volume = {23},
	issn = {1433-7479},
	url = {https://doi.org/10.1007/s00500-017-2888-9},
	doi = {10.1007/s00500-017-2888-9},
	abstract = {A novel mesh-free heuristic method for solving differential equations is proposed. The new approach can cope with linear, nonlinear, and partial differential equations (DE), and systems of DEs. Candidate solutions are expressed using a linear combination of kernel functions. Thus, the original problem is transformed into an optimization problem that consists in finding the parameters that define each kernel. The new optimization problem is solved applying a Covariance Matrix Adaptation Evolution Strategy. To increase the accuracy of the results, a Downhill Simplex local search is applied to the best solution found by the mentioned evolutionary algorithm. Our method is applied to 32 differential equations extracted from the literature. All problems are successfully solved, achieving competitive accuracy levels when compared to other heuristic methods. A simple comparison with numerical methods is performed using two partial differential equations to show the pros and cons of the proposed algorithm. To verify the potential of this approach with a more practical problem, an electric circuit is analyzed in depth. The method can obtain the dynamic behavior of the circuit in a parametric way, taking into account different component values.},
	language = {en},
	number = {5},
	urldate = {2020-03-02},
	journal = {Soft Computing},
	author = {Chaquet, Jose M. and Carmona, Enrique J.},
	month = mar,
	year = {2019},
	keywords = {Good Quality, CMA-ES, Radial Basis Functions, Literature Survey},
	pages = {1643--1666},
	annote = {used CMA-ES coupled with the local search of a downhill simplex algorithm
candidates are represented as a linear combination of gaussian kernels
fitness function with formula
extensive testbed of 32 differential equations
downhill search is proven useful with statistical significance
 },
	file = {Chaquet und Carmona - 2019 - Using Covariance Matrix Adaptation Evolution Strat.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\YKK6UD9T\\Chaquet und Carmona - 2019 - Using Covariance Matrix Adaptation Evolution Strat.pdf:application/pdf}
}

@article{sadollah_metaheuristic_2017,
	title = {Metaheuristic optimisation methods for approximate solving of singular boundary value problems},
	volume = {29},
	issn = {0952-813X},
	url = {https://doi.org/10.1080/0952813X.2016.1259271},
	doi = {10.1080/0952813X.2016.1259271},
	abstract = {This paper presents a novel approximation technique based on metaheuristics and weighted residual function (WRF) for tackling singular boundary value problems (BVPs) arising in engineering and science. With the aid of certain fundamental concepts of mathematics, Fourier series expansion, and metaheuristic optimisation algorithms, singular BVPs can be approximated as an optimisation problem with boundary conditions as constraints. The target is to minimise the WRF (i.e. error function) constructed in approximation of BVPs. The scheme involves generational distance metric for quality evaluation of the approximate solutions against exact solutions (i.e. error evaluator metric). Four test problems including two linear and two non-linear singular BVPs are considered in this paper to check the efficiency and accuracy of the proposed algorithm. The optimisation task is performed using three different optimisers including the particle swarm optimisation, the water cycle algorithm, and the harmony search algorithm. Optimisation results obtained show that the suggested technique can be successfully applied for approximate solving of singular BVPs.},
	number = {4},
	urldate = {2020-03-02},
	journal = {Journal of Experimental \& Theoretical Artificial Intelligence},
	author = {Sadollah, Ali and Yadav, Neha and Gao, Kaizhou and Su, Rong},
	month = jul,
	year = {2017},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/0952813X.2016.1259271},
	keywords = {Good Quality, Fourier Series, Particle Swarm Optimisation, Harmony Search, Water Cycle Algorithm},
	pages = {823--842},
	annote = {comparison to deterministic algorithm:
Adomian Decomposition Method},
	file = {Sadollah et al. - 2017 - Metaheuristic optimisation methods for approximate.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\96ZHFX98\\Sadollah et al. - 2017 - Metaheuristic optimisation methods for approximate.pdf:application/pdf}
}

@article{kirstukas_hybrid_2005,
	title = {A hybrid genetic programming approach for the analytical solution of differential equations},
	volume = {34},
	issn = {0308-1079},
	url = {https://doi.org/10.1080/03081070500065676},
	doi = {10.1080/03081070500065676},
	abstract = {This paper presents a novel addition to the current genetic programming techniques for solving differential equations. Rather than using numerical approximation of derivatives during fitness evaluation, automatically computed analytical derivatives of the candidate solutions are employed. Because analytical derivatives are used, symbolic constants can be incorporated in the solution. This permits the development of a single solution for a range of material properties, boundary conditions or other design parameters. Additionally, for the special case of linear differential equations, a modified Gram–Schmidt algorithm is used to reduce the set of general solutions located by genetic programming to a basis set.},
	number = {3},
	urldate = {2020-03-02},
	journal = {International Journal of General Systems},
	author = {Kirstukas, Steven J. and Bryden, Kenneth M. and Ashlock, Daniel A.},
	month = jun,
	year = {2005},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/03081070500065676},
	keywords = {Genetic Programming, Gram-Schmitt},
	pages = {279--299},
	annote = {The first step is relatively time consuming and employs genetic programming techniques to findbasis functions that span the solution space. The second step is very fast and uses a Gram–Schmidt algorithm to compute the basis function multipliers to develop a complete solutionfor a given set of boundary conditions. Using linear solver methods, a set of coefficients is found that produces a single function that both satisfies the differential equation and the boundary or initial conditions at all evaluationpoints.},
	file = {Kirstukas et al. - 2005 - A hybrid genetic programming approach for the anal.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\7ILYD4BM\\Kirstukas et al. - 2005 - A hybrid genetic programming approach for the anal.pdf:application/pdf}
}

@article{chaquet_solving_2012,
	title = {Solving differential equations with {Fourier} series and {Evolution} {Strategies}},
	volume = {12},
	issn = {1568-4946},
	url = {http://www.sciencedirect.com/science/article/pii/S1568494612002505},
	doi = {10.1016/j.asoc.2012.05.014},
	abstract = {A novel mesh-free approach for solving differential equations based on Evolution Strategies (ESs) is presented. Any structure is assumed in the equations making the process general and suitable for linear and nonlinear ordinary and partial differential equations (ODEs and PDEs), as well as systems of ordinary differential equations (SODEs). Candidate solutions are expressed as partial sums of Fourier series. Taking advantage of the decreasing absolute value of the harmonic coefficients with the harmonic order, several ES steps are performed. Harmonic coefficients are taken into account one by one starting with the lower order ones. Experimental results are reported on several problems extracted from the literature to illustrate the potential of the proposed approach. Two cases (an initial value problem and a boundary condition problem) have been solved using numerical methods and a quantitative comparative is performed. In terms of accuracy and storing requirements the proposed approach outperforms the numerical algorithm.},
	language = {en},
	number = {9},
	urldate = {2020-03-02},
	journal = {Applied Soft Computing},
	author = {Chaquet, Jose M. and Carmona, Enrique J.},
	month = sep,
	year = {2012},
	keywords = {Evolution Strategies, Good Quality, Fourier Series, Literature Survey},
	pages = {3051--3062},
	annote = {uses a selfadaptive-ES to evolve the coefficients of a partial Fourier series
they leverage the idea, that the coefficiets decrease with increasing order to freeze coefficents and decrease the search dimension
the algorithm is then tested on an extensive testbed of multiple differential equations
for comparison against the analytical solution, a root mean square quality measure over discretised points is used is used
 
 },
	file = {Chaquet und Carmona - 2012 - Solving differential equations with Fourier series.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\V8A3RWU5\\Chaquet und Carmona - 2012 - Solving differential equations with Fourier series.pdf:application/pdf}
}

@article{opara_differential_2019,
	title = {Differential {Evolution}: {A} survey of theoretical analyses},
	volume = {44},
	issn = {2210-6502},
	shorttitle = {Differential {Evolution}},
	url = {http://www.sciencedirect.com/science/article/pii/S2210650217304224},
	doi = {10.1016/j.swevo.2018.06.010},
	abstract = {Differential Evolution (DE) is a state-of-the art global optimization technique. Considerable research effort has been made to improve this algorithm and apply it to a variety of practical problems. Nevertheless, analytical studies concerning DE are rather rare. This paper surveys the theoretical results obtained so far for DE. A discussion of genetic operators characteristic of DE is coupled with an overview of the population diversity and dynamics models. A comprehensive view on the current-day understanding of the underlying mechanisms of DE is complemented by a list of promising research directions.},
	language = {en},
	urldate = {2020-03-04},
	journal = {Swarm and Evolutionary Computation},
	author = {Opara, Karol R. and Arabas, Jarosław},
	month = feb,
	year = {2019},
	pages = {546--558},
	file = {Opara und Arabas - 2019 - Differential Evolution A survey of theoretical an.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\BIP4ZJ4X\\Opara und Arabas - 2019 - Differential Evolution A survey of theoretical an.pdf:application/pdf}
}

@article{howard_genetic_2011,
	title = {Genetic programming of the stochastic interpolation framework: convection–diffusion equation},
	volume = {15},
	issn = {1433-7479},
	shorttitle = {Genetic programming of the stochastic interpolation framework},
	url = {https://doi.org/10.1007/s00500-009-0520-3},
	doi = {10.1007/s00500-009-0520-3},
	abstract = {The stochastic interpolation (SI) framework of function recovery from input data comprises a de-convolution step followed by a convolution step with row stochastic matrices generated by a mollifier, such as a probability density function. The choice of a mollifier and of how it gets weighted, offers unprecedented flexibility to vary both the interpolation character and the extent of influence of neighbouring data values. In this respect, a soft computing method such as a genetic algorithm or heuristic method may assist applications that model complex or unknown relationships between data by tuning the parameters, functional and component choices inherent in SI. Alternatively or additionally, the input data itself can be reverse engineered to recover a function that satisfies properties, as illustrated in this paper with a genetic programming scheme that enables SI to recover the analytical solution to a two-point boundary value convection–diffusion differential equation. If further developed, this nascent solution method could serve as an alternative to the weighted residual methods, as these are known to have inherent mathematical difficulties.},
	language = {en},
	number = {1},
	urldate = {2020-03-14},
	journal = {Soft Computing},
	author = {Howard, Daniel and Brezulianu, Adrian and Kolibal, Joseph},
	month = jan,
	year = {2011},
	keywords = {Finite Difference, Genetic Programming},
	pages = {71--78},
	annote = {grid points for function evaluation and grid points of candidate solution are not the same:
candidate: linear spaced over boundaryfunction evaluation: latin sampling},
	file = {Howard et al. - 2011 - Genetic programming of the stochastic interpolatio.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\W5PFUCHX\\Howard et al. - 2011 - Genetic programming of the stochastic interpolatio.pdf:application/pdf}
}

@article{sobester_genetic_2008,
	title = {Genetic {Programming} {Approaches} for {Solving} {Elliptic} {Partial} {Differential} {Equations}},
	volume = {12},
	issn = {1941-0026},
	doi = {10.1109/TEVC.2007.908467},
	abstract = {In this paper, we propose a technique based on genetic programming (GP) for meshfree solution of elliptic partial differential equations. We employ the least-squares collocation principle to define an appropriate objective function, which is optimized using GP. Two approaches are presented for the repair of the symbolic expression for the field variables evolved by the GP algorithm to ensure that the governing equations as well as the boundary conditions are satisfied. In the case of problems defined on geometrically simple domains, we augment the solution evolved by GP with additional terms, such that the boundary conditions are satisfied by construction. To satisfy the boundary conditions for geometrically irregular domains, we combine the GP model with a radial basis function network. We improve the computational efficiency and accuracy of both techniques with gradient boosting, a technique originally developed by the machine learning community. Numerical studies are presented for operator problems on regular and irregular boundaries to illustrate the performance of the proposed algorithms.},
	number = {4},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Sobester, AndrÁs and Nair, Prasanth B. and Keane, Andy J.},
	month = aug,
	year = {2008},
	note = {Conference Name: IEEE Transactions on Evolutionary Computation},
	keywords = {Good Quality, Genetic Programming},
	pages = {469--478},
	annote = {using the collocation point method incorporate the boundary condition is not effective
thus, they use a radial basis function network to repair the initially developed solution of the gp and add the basis function to the solution
formel: û(x) = uGP + uRBF
provided that the boundary operator is linear, the problem of finding the correct RBF can be transformed into a least squares problem
 
 
 
 },
	file = {Sobester et al. - 2008 - Genetic Programming Approaches for Solving Ellipti.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\MQ7Q5N76\\Sobester et al. - 2008 - Genetic Programming Approaches for Solving Ellipti.pdf:application/pdf}
}

@book{finlayson_method_2013,
	series = {Classics in {Applied} {Mathematics}},
	title = {The {Method} of {Weighted} {Residuals} and {Variational} {Principles}},
	isbn = {978-1-61197-323-5},
	url = {https://epubs.siam.org/doi/book/10.1137/1.9781611973242},
	abstract = {This is a book for people who want to solve problems formulated as differential equations in science and engineering. The subject area is limited to fluid mechanics, heat and mass transfer. While making no pretense at completely covering these subjects and their relationship to variational principles and approximate methods, the book is intended to give the novice an introduction to the subject, and lead him through the difficult research problems being treated in the current literature. The first four chapters give a relatively simple treatment of many classical problems in the field. The literature is full of simple, one-term approximations, but the method of weighted residuals (MWR) can be used to obtain answers of any desired accuracy, and there are several methods specifically adapted to the computer. In many test cases MWR compares favorably to finite difference computations in that the MWR results are either more accurate or require less computation time to generate or both. Chapter 4 discusses the developments by Professor D. E. Abbott and his students at Purdue University on laminar boundary layer flows. Orthogonal collocation is illustrated in Chapter 5. This method was advanced in 1967 by Professor W. E. Stewart at the University of Wisconsin and J. V. Villadsen at Danmarks Tekniske Højskole, It drastically reduces the drudgery of setting up the problem, and, when applicable, is highly recommended. Chapter 6 studies the Galerkin method as applied to convective instability problems, where it proves effective and accurate. Chapters 5 and 7 relate MWR to finite element methods, which is a promising technique, especially for linear problems with irregular boundaries.},
	urldate = {2020-03-19},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Finlayson, Bruce A.},
	month = dec,
	year = {2013},
	doi = {10.1137/1.9781611973242},
	file = {Finlayson - 2013 - The Method of Weighted Residuals and Variational P.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\M9E3HYQI\\Finlayson - 2013 - The Method of Weighted Residuals and Variational P.pdf:application/pdf}
}

@misc{suganthan_suganthancec2019_2020,
	title = {Suganthan/{CEC2019}},
	url = {https://github.com/P-N-Suganthan/CEC2019},
	abstract = {100-Digit Competition. This folder includes GECCO 2019 and SEMCCO 2019 too, in addition to CEC 2019},
	urldate = {2020-03-20},
	author = {Suganthan},
	month = jan,
	year = {2020},
	note = {original-date: 2019-07-01T11:46:13Z}
}

@inproceedings{tanabe_success-history_2013,
	title = {Success-history based parameter adaptation for {Differential} {Evolution}},
	doi = {10.1109/CEC.2013.6557555},
	abstract = {Differential Evolution is a simple, but effective approach for numerical optimization. Since the search efficiency of DE depends significantly on its control parameter settings, there has been much recent work on developing self-adaptive mechanisms for DE. We propose a new, parameter adaptation technique for DE which uses a historical memory of successful control parameter settings to guide the selection of future control parameter values. The proposed method is evaluated by comparison on 28 problems from the CEC2013 benchmark set, as well as CEC2005 benchmarks and the set of 13 classical benchmark problems. The experimental results show that a DE using our success-history based parameter adaptation method is competitive with the state-of-the-art DE algorithms.},
	booktitle = {2013 {IEEE} {Congress} on {Evolutionary} {Computation}},
	author = {Tanabe, Ryoji and Fukunaga, Alex},
	month = jun,
	year = {2013},
	note = {ISSN: 1941-0026},
	pages = {71--78},
	file = {Tanabe und Fukunaga - 2013 - Success-history based parameter adaptation for Dif.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\T5YTE4LJ\\Tanabe und Fukunaga - 2013 - Success-history based parameter adaptation for Dif.pdf:application/pdf}
}

@article{zhang_jade_2009,
	title = {{JADE}: {Adaptive} {Differential} {Evolution} {With} {Optional} {External} {Archive}},
	volume = {13},
	issn = {1941-0026},
	shorttitle = {{JADE}},
	doi = {10.1109/TEVC.2009.2014613},
	abstract = {A new differential evolution (DE) algorithm, JADE, is proposed to improve optimization performance by implementing a new mutation strategy ldquoDE/current-to-p bestrdquo with optional external archive and updating control parameters in an adaptive manner. The DE/current-to-pbest is a generalization of the classic ldquoDE/current-to-best,rdquo while the optional archive operation utilizes historical data to provide information of progress direction. Both operations diversify the population and improve the convergence performance. The parameter adaptation automatically updates the control parameters to appropriate values and avoids a user's prior knowledge of the relationship between the parameter settings and the characteristics of optimization problems. It is thus helpful to improve the robustness of the algorithm. Simulation results show that JADE is better than, or at least comparable to, other classic or adaptive DE algorithms, the canonical particle swarm optimization, and other evolutionary algorithms from the literature in terms of convergence performance for a set of 20 benchmark problems. JADE with an external archive shows promising results for relatively high dimensional problems. In addition, it clearly shows that there is no fixed control parameter setting suitable for various problems or even at different optimization stages of a single problem.},
	number = {5},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Zhang, Jingqiao and Sanderson, Arthur C.},
	month = oct,
	year = {2009},
	note = {Conference Name: IEEE Transactions on Evolutionary Computation},
	pages = {945--958},
	file = {Zhang und Sanderson - 2009 - JADE Adaptive Differential Evolution With Optiona.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\ZVTQN6TQ\\Zhang und Sanderson - 2009 - JADE Adaptive Differential Evolution With Optiona.pdf:application/pdf}
}

@article{rajeev_discrete_1992,
	title = {Discrete {Optimization} of {Structures} {Using} {Genetic} {Algorithms}},
	volume = {118},
	url = {https://ascelibrary.org/doi/abs/10.1061/(ASCE)0733-9445(1992)118:5(1233)},
	doi = {10.1061/(ASCE)0733-9445(1992)118:5(1233)},
	number = {5},
	urldate = {2020-03-23},
	journal = {Journal of Structural Engineering},
	author = {{Rajeev} and {Krishnamoorthy}},
	month = may,
	year = {1992},
	note = {Publisher: American Society of Civil Engineers},
	pages = {1233--1250},
	file = {Rajeev S. und Krishnamoorthy C. S. - 1992 - Discrete Optimization of Structures Using Genetic .pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\Q6N9E6ZJ\\Rajeev S. und Krishnamoorthy C. S. - 1992 - Discrete Optimization of Structures Using Genetic .pdf:application/pdf}
}

@misc{schoberl_ngsolvengsolve_2020,
	title = {{NGSolve}/ngsolve},
	copyright = {LGPL-2.1},
	url = {https://github.com/NGSolve/ngsolve},
	abstract = {Netgen/NGSolve is a high performance multiphysics finite element software. It is widely used to analyze models from solid mechanics, fluid dynamics and electromagnetics. Due to its flexible Pytho...},
	urldate = {2020-04-02},
	publisher = {NGSolve},
	author = {Schöberl, Joachim and Lackner, Christopher and Hochsteger, Matthias},
	month = apr,
	year = {2020},
	note = {original-date: 2017-07-18T08:47:19Z}
}

@article{nelder_simplex_1965,
	title = {A {Simplex} {Method} for {Function} {Minimization}},
	volume = {7},
	issn = {0010-4620},
	url = {https://academic.oup.com/comjnl/article/7/4/308/354237},
	doi = {10.1093/comjnl/7.4.308},
	abstract = {Abstract.  A method is described for the minimization of a function of n variables, which depends on the comparison of function values at the (n + 1) vertices o},
	language = {en},
	number = {4},
	urldate = {2020-05-05},
	journal = {The Computer Journal},
	author = {Nelder, J. A. and Mead, R.},
	month = jan,
	year = {1965},
	note = {Publisher: Oxford Academic},
	pages = {308--313},
	file = {Nelder und Mead - 1965 - A Simplex Method for Function Minimization.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\QAL2B4HN\\Nelder und Mead - 1965 - A Simplex Method for Function Minimization.pdf:application/pdf}
}

@inproceedings{kennedy_particle_1995,
	title = {Particle swarm optimization},
	volume = {4},
	doi = {10.1109/ICNN.1995.488968},
	abstract = {A concept for the optimization of nonlinear functions using particle swarm methodology is introduced. The evolution of several paradigms is outlined, and an implementation of one of the paradigms is discussed. Benchmark testing of the paradigm is described, and applications, including nonlinear function optimization and neural network training, are proposed. The relationships between particle swarm optimization and both artificial life and genetic algorithms are described.},
	booktitle = {Proceedings of {ICNN}'95 - {International} {Conference} on {Neural} {Networks}},
	author = {Kennedy, J. and Eberhart, R.},
	month = nov,
	year = {1995},
	pages = {1942--1948 vol.4},
	file = {Kennedy und Eberhart - 1995 - Particle swarm optimization.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\3EM6ZM54\\Kennedy und Eberhart - 1995 - Particle swarm optimization.pdf:application/pdf}
}

@book{koza_genetic_1992,
	address = {Cambridge, MA, USA},
	title = {Genetic programming: on the programming of computers by means of natural selection},
	isbn = {978-0-262-11170-6},
	shorttitle = {Genetic programming},
	publisher = {MIT Press},
	author = {Koza, John R.},
	year = {1992},
	file = {Koza - 1992 - Genetic programming on the programming of compute.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\TYMVAE23\\Koza - 1992 - Genetic programming on the programming of compute.pdf:application/pdf}
}

@article{geem_new_2001,
	title = {A {New} {Heuristic} {Optimization} {Algorithm}: {Harmony} {Search}},
	volume = {76},
	issn = {0037-5497},
	shorttitle = {A {New} {Heuristic} {Optimization} {Algorithm}},
	url = {https://doi.org/10.1177/003754970107600201},
	doi = {10.1177/003754970107600201},
	abstract = {Many optimization problems in various fields have been solved using diverse optimization al gorithms. Traditional optimization techniques such as linear programming (LP), non-linear programming (NLP), and dynamic program ming (DP) have had major roles in solving these problems. However, their drawbacks generate demand for other types of algorithms, such as heuristic optimization approaches (simulated annealing, tabu search, and evolutionary algo rithms). However, there are still some possibili ties of devising new heuristic algorithms based on analogies with natural or artificial phenom ena. A new heuristic algorithm, mimicking the improvisation of music players, has been devel oped and named Harmony Search (HS). The performance of the algorithm is illustrated with a traveling salesman problem (TSP), a specific academic optimization problem, and a least-cost pipe network design problem.},
	language = {en},
	number = {2},
	urldate = {2020-05-05},
	journal = {SIMULATION},
	author = {Geem, Zong Woo and Kim, Joong Hoon and Loganathan, G.V.},
	month = feb,
	year = {2001},
	note = {Publisher: SAGE Publications Ltd STM},
	pages = {60--68},
	file = {Geem et al. - 2001 - A New Heuristic Optimization Algorithm Harmony Se.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\RH63AXP7\\Geem et al. - 2001 - A New Heuristic Optimization Algorithm Harmony Se.pdf:application/pdf}
}

@article{eskandar_water_2012,
	title = {Water cycle algorithm – {A} novel metaheuristic optimization method for solving constrained engineering optimization problems},
	volume = {110-111},
	issn = {0045-7949},
	url = {http://www.sciencedirect.com/science/article/pii/S0045794912001770},
	doi = {10.1016/j.compstruc.2012.07.010},
	abstract = {This paper presents a new optimization technique called water cycle algorithm (WCA) which is applied to a number of constrained optimization and engineering design problems. The fundamental concepts and ideas which underlie the proposed method is inspired from nature and based on the observation of water cycle process and how rivers and streams flow to the sea in the real world. A comparative study has been carried out to show the effectiveness of the WCA over other well-known optimizers in terms of computational effort (measures as number of function evaluations) and function value (accuracy) in this paper.},
	language = {en},
	urldate = {2020-05-05},
	journal = {Computers \& Structures},
	author = {Eskandar, Hadi and Sadollah, Ali and Bahreininejad, Ardeshir and Hamdi, Mohd},
	month = nov,
	year = {2012},
	pages = {151--166},
	file = {Eskandar et al. - 2012 - Water cycle algorithm – A novel metaheuristic opti.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\TIKHFMZA\\Eskandar et al. - 2012 - Water cycle algorithm – A novel metaheuristic opti.pdf:application/pdf}
}

@inproceedings{ryan_grammatical_1998,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Grammatical evolution: {Evolving} programs for an arbitrary language},
	isbn = {978-3-540-69758-9},
	shorttitle = {Grammatical evolution},
	doi = {10.1007/BFb0055930},
	abstract = {We describe a Genetic Algorithm that can evolve complete programs. Using a variable length linear genome to govern how a Backus Naur Form grammar definition is mapped to a program, expressions and programs of arbitrary complexity may be evolved. Other automatic programming methods are described, before our system, Grammatical Evolution, is applied to a symbolic regression problem.},
	language = {en},
	booktitle = {Genetic {Programming}},
	publisher = {Springer},
	author = {Ryan, Conor and Collins, JJ and Neill, Michael O.},
	editor = {Banzhaf, Wolfgang and Poli, Riccardo and Schoenauer, Marc and Fogarty, Terence C.},
	year = {1998},
	pages = {83--96},
	file = {Ryan et al. - 1998 - Grammatical evolution Evolving programs for an ar.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\9HR6ANDN\\Ryan et al. - 1998 - Grammatical evolution Evolving programs for an ar.pdf:application/pdf}
}

@incollection{schwefel_evolutionsstrategien_1977,
	address = {Basel},
	series = {Interdisciplinary {Systems} {Research} / {Interdisziplinäre} {Systemforschung}},
	title = {Evolutionsstrategien für die numerische {Optimierung}},
	isbn = {978-3-0348-5927-1},
	url = {https://doi.org/10.1007/978-3-0348-5927-1_5},
	abstract = {Das Unterfangen, biologische Strukturen und Prozesse nachzuahmen, mit dem Ziel, technische Aufgaben zu bewältigen, ist so alt wie die Technik selbst. Die Sage von Dädalus und Ikarus ist ein frühes Zeugnis solchen menschlichen Bestrebens. Im Zeichen der Verwissenschaftlichung hat sich daraus ein eigener Zweig der Naturwissenschaften gebildet: die Bionik (siehe z.B. Hertel (1963), Gérardin (1968), Beier und Glaß (1968), Nachtigall (1971), Heynert (1972)). In ihr geht es um das Erkennen (vorliegender) biologischer Lösungen für bestimmte, in der Technik ebenfalls auftretende Aufgabenstellungen und um adäquate Nachahmung der Vorbilder. Ausgegangen wird dabei stets von der Vermutung, daß die Evolution besonders gute, eventuell sogar optimale, Lösungen gefunden hat. Diese Annahme hat sich in vielen Fällen als richtig bzw.nützlich erwiesen. Nur wenige Bemühungen sind bekannt, die Entwicklungsmethode der Natur selbst nachzuahmen (Ashby (1960), Bremermann (1962–1973), Rechenberg (1964,1973); siehe auch Kapitel 4), weil sie seltsamerweise von vornherein als besonders schlecht, das heißt aufwendig, angesehen wird.},
	language = {de},
	urldate = {2020-05-29},
	booktitle = {Numerische {Optimierung} von {Computer}-{Modellen} mittels der {Evolutionsstrategie}: {Mit} einer vergleichenden {Einführung} in die {Hill}-{Climbing}- und {Zufallsstrategie}},
	publisher = {Birkhäuser},
	author = {Schwefel, Hans-Paul},
	editor = {Schwefel, Hans-Paul},
	year = {1977},
	doi = {10.1007/978-3-0348-5927-1_5},
	pages = {123--176}
}

@inproceedings{rechenberg_evolutionsstrategien_1978,
	address = {Berlin, Heidelberg},
	series = {Medizinische {Informatik} und {Statistik}},
	title = {Evolutionsstrategien},
	isbn = {978-3-642-81283-5},
	doi = {10.1007/978-3-642-81283-5_8},
	abstract = {Die Tatsache, daß sich die Tier- und Pflanzenwelt durch Evolution allmählich entwickelt hat, wird gegenwärtig kaum noch in Zweifel gestellt. Meinungsverschiedenheiten gibt es aber auch heute noch bezüglich der Ursachen der Evolution. So wird verschiedentlich argumentiert, die Darwinsche Evolutionshypothese der zufälligen Variation und Auslese des Besseren beinhalte einen Zirkelschluß. Denn auf die Frage: „Wer überlebt?“, wird geantwortet: „Wer am tauglichsten ist“. Und auf die Frage: „Wer ist am tauglichsten?“, folgt wieder die Antwort: „Derjenige, der überlebt“. — Zweifel an der darwinistischen Erklärung der biologischen Evolution äußern häufig gerade die Vertreter der exaktesten Wissenschaften, Mathematiker und Physiker. Ihr Einwand lautet: Fünf Milliarden Jahre sind einfach zu wenig,um die Mannigfaltigkeit der so wunderbar angepaßten Tier- und Pflanzenwelt zu erklären. Bei dem Versuch, den Evolutionsvorgang mathematisch nachzuvollziehen, kommen diese Wissenschaftler vielfach zu Zeitskalen, für die 5 Milliarden Jahre, die höchstens auf der Erde verfügbar waren, niemals ausreichen würden.},
	language = {de},
	booktitle = {Simulationsmethoden in der {Medizin} und {Biologie}},
	publisher = {Springer},
	author = {Rechenberg, I.},
	editor = {Schneider, Berthold and Ranft, Ulrich},
	year = {1978},
	pages = {83--114}
}

@article{holland_outline_1962,
	title = {Outline for a {Logical} {Theory} of {Adaptive} {Systems}},
	volume = {9},
	issn = {0004-5411},
	url = {https://doi.org/10.1145/321127.321128},
	doi = {10.1145/321127.321128},
	number = {3},
	urldate = {2020-05-29},
	journal = {Journal of the ACM},
	author = {Holland, John H.},
	month = jul,
	year = {1962},
	pages = {297--314}
}

@article{guyan_reduction_1965,
	title = {Reduction of stiffness and mass matrices},
	doi = {10.2514/3.2874},
	abstract = {Just as it is often necessary to reduce the size of the stiff­ness matrix in statical structural analysis, the simulta­neous reduction of the nondiagonal mass matrix for natural mode analysis may also be required. The basis for one such reduction technique may follow the procedure used in Ref. 1 for the stiffness matrix, namely, the elimination of coordinates at which no forces are applied.},
	journal = {AIAAJ Aeronautics {\textbar} Astronautics},
	author = {Guyan, R. J.},
	year = {1965},
	pages = {380},
	file = {Guyan - 1965 - Reduction of stiffness and mass matrices.pdf:C\:\\Users\\Admin\\OneDrive\\FH Mechatronik\\Literaturquellen\\storage\\FUIJFALD\\Guyan - 1965 - Reduction of stiffness and mass matrices.pdf:application/pdf}
}

@article{hansen_reducing_2003,
	title = {Reducing the {Time} {Complexity} of the {Derandomized} {Evolution} {Strategy} with {Covariance} {Matrix} {Adaptation} ({CMA}-{ES})},
	volume = {11},
	issn = {1063-6560},
	url = {https://doi.org/10.1162/106365603321828970},
	doi = {10.1162/106365603321828970},
	abstract = {This paper presents a novel evolutionary optimization strategy based on the derandomized evolution strategy with covariance matrix adaptation (CMA-ES). This new approach is intended to reduce the number of generations required for convergence to the optimum. Reducing the number of generations, i.e., the time complexity of the algorithm, is important if a large population size is desired: (1) to reduce the effect of noise; (2) to improve global search properties; and (3) to implement the algorithm on (highly) parallel machines. Our method results in a highly parallel algorithm which scales favorably with large numbers of processors. This is accomplished by efficiently incorporating the available information from a large population, thus significantly reducing the number of generations needed to adapt the covariance matrix. The original version of the CMA-ES was designed to reliably adapt the covariance matrix in small populations but it cannot exploit large populations efficiently. Our modifications scale up the efficiency to population sizes of up to 10n, where n is the problem dimension. This method has been applied to a large number of test problems, demonstrating that in many cases the CMA-ES can be advanced from quadratic to linear time complexity.},
	number = {1},
	urldate = {2020-08-15},
	journal = {Evolutionary Computation},
	author = {Hansen, Nikolaus and Müller, Sibylle D. and Koumoutsakos, Petros},
	month = mar,
	year = {2003},
	note = {Publisher: MIT Press},
	pages = {1--18}
}
